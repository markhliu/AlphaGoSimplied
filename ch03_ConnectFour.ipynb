{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653089c9",
   "metadata": {},
   "source": [
    "# Chapter 3: Rule-Based AI in Connect Four\n",
    "\n",
    "We'll first create a game environment for the popular everyday game Connect Four in this chapter. Similar to what we have done in Chapter 2, we'll create AI players in this game. Specifically, we'll hard code in some rules to make the AI player think up to three steps ahead. You'll then deploy the strategies against a random player or against each other to see how effective they are. As we discussed in Chapter 2, coding in rule-based AI serves several purposes. Other than learning to build rule-based AI and generalize it to real-world situations, you'll learn to create a game environment for Connect Four that has all the attributes and methods of a typical OpenAI Gym game environment. You'll also use Connect Four to study other AI algorithms later in this book, such as MiniMax, Monte Carlo Tree Search, Actor-Critic. You'll also use rule-based AI to train AlphaGo agents later in this book and use rule-based AI as benchmarks to test teh effectiveness of other AI algorithms.\n",
    "\n",
    "When the AI player thinks one step ahead, it iterates through all possible next moves and check if any one of them leads to winning the game right away. If yes, the AI player will take the move. This is very similar to what we have done in the game of Tic Tac Toe. However, thinking two steps ahead in Connect Four is a bit more complicated. The AI player’s next move can either block the opponent or help the opponent’s chance of winning the game on the next turn. We’ll separate these two cases: if the AI player’s move blocks the opponent’s chance of winning, the AI player will take it. On the other hand, if the AI palyer’s move helps the opponent’s chance of winning, the game strategy will avoid the move so the the opponent won't win two steps ahead. By thinking three steps ahead, the AI player follows the path that most likely leads to a victory after three moves. In some cases, thinking three steps ahead can guarantee a win for the AI player in three steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b25bf6",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Create a subfolder for files in Chapter 3}}$<br>\n",
    "***\n",
    "We'll put all files in Chapter 3 in a subfolder /files/ch03. Run the code in the cell below to create the subfolder.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117477d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"files/ch03\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ad876",
   "metadata": {},
   "source": [
    "# 1. Create the Connect Four Game Environment\n",
    "We'll create a Connect Four game environment, using the ***turtle*** library to draw game boards. We’ll create all the features and methods that a typical OpenAI Gym environment has. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c437e8",
   "metadata": {},
   "source": [
    "## 1.1. Use A Python Class to Represent the Environment\n",
    "We’ll create a Python class to represent the Connect Four game environment. The class will have various attributes, variables, and methods to replicate those in a typical OpenAI Gym game environment. \n",
    "\n",
    "### Attributes\n",
    "Specifically, our self-made Connect Four game environment will have the following attributes:\n",
    " \n",
    "*\taction_space: an attribute that provides the space of all actions that can be taken by the agent. The action space will have seven values, 1 to 7. This represents the 7 columns a player can drop discs in.\n",
    "*\tobservation_space: an attribute that provides the list of all possible states in the environment. We'll use a numpy array with 7 rows and 6 columns to represent the 42 cells on a game board.\n",
    "*\tstate: an attribute indicating which state the agent is currently in. Each of the 42 cells can take values -1 (occupied by player Yellow), 0 (empty), or 1 (occupied by player Red).\n",
    "*\taction: an attribute indicating the action taken by the agent. The action is a number between 1 and 7.\n",
    "*\treward: an attribute indicating the reward to the agent because of the action taken by the agent. The reward is 0 in each step, unless a player has won the game, in which case the winner has a reward of 1 and the loser a reward of -1. \n",
    "*\tdone: an attribute indicating whether the game has ended. This happens when one player wins or if the game is tied.\n",
    "*\tinfo: an attribute that provides information about the game. We'll set it as an empty string \"\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f9996e",
   "metadata": {},
   "source": [
    "### Methods\n",
    "Our self-made Connect Four game environment will have a few methods as well:\n",
    " \n",
    "*\treset() is a method to set the game environment to the initial (that is, the starting) state. All cells on the board will be empty.\n",
    "*\trender() is a method showing the current state of the environment graphically.\n",
    "*\tstep() is a method that returns the new state, the reward, the value of *done* variable, and the variable *info* based on the action taken by the agent.\n",
    "*\tsample() is a method to randomly choose an action from the action space.\n",
    "*\tclose() is a method to end the game environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d7767",
   "metadata": {},
   "source": [
    "## 1.2. Create A Local Module for the Connect Four Game\n",
    "We'll create a local module for the Connect Four game and place it inside the local package for this book: the package ***utils*** that we have created in Chapter 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7252a608",
   "metadata": {},
   "source": [
    "Now let's code in a self-made Connect Four game environment using a Python class. Save the code in the cell below as *conn_env.py* in the folder *utils* you created in Chapter 1. Alternatively, you can download it from my GitHub repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9c644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import turtle as t\n",
    "from random import choice\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Define an action_space helper class\n",
    "class action_space:\n",
    "    ... \n",
    "# Define an obervation_space helper class    \n",
    "class observation_space:\n",
    "    ...\n",
    "class conn():\n",
    "    ...    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05110e83",
   "metadata": {},
   "source": [
    "If you run the above cell, nothing will happen. The class simply creates a game environment. We need to initiate the game environment and start playing using Python programs, just as you do with an OpenAI Gym game environment. We'll do that in the next subsection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee28a4e",
   "metadata": {},
   "source": [
    "## 1.3. Verify the Custom-Made Game Environment\n",
    "Next, we'll check the attributes and methods of the self-made game environment and make sure it has all the elements that are provided by a typical OpenAI Gym game environment. \n",
    "\n",
    "First we'll initiate the game environment and show the game board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a847d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.conn_env import conn\n",
    "\n",
    "env = conn()\n",
    "env.reset()                    \n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6bd0a",
   "metadata": {},
   "source": [
    "You should see a separate turtle window, with a game board as follows: \n",
    "<img src=\"https://gattonweb.uky.edu/faculty/lium/ml/conn_start.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977029b",
   "metadata": {},
   "source": [
    "If you want to close the game board window, use the *close()* method, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "439f093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d963a4e3",
   "metadata": {},
   "source": [
    "Next, we'll check the attributes of the environment such as the observation space and action space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b9c0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of possible actions are 7\n",
      "the following are ten sample actions\n",
      "7\n",
      "6\n",
      "6\n",
      "1\n",
      "6\n",
      "5\n",
      "7\n",
      "3\n",
      "4\n",
      "5\n",
      "the shape of the observation space is (7, 6)\n"
     ]
    }
   ],
   "source": [
    "env=conn()\n",
    "# check the action space\n",
    "number_actions=env.action_space.n\n",
    "print(\"the number of possible actions are\",number_actions)\n",
    "# sample the action space ten times\n",
    "print(\"the following are ten sample actions\")\n",
    "for i in range(10):\n",
    "   print(env.action_space.sample())\n",
    "# check the shape of the observation space\n",
    "print(\"the shape of the observation space is\",\\\n",
    "      env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2033eed1",
   "metadata": {},
   "source": [
    "The meanings of the actions in this game are as follows\n",
    "* 1: Placing a game piece in column 1\n",
    "* 2: Placing a game piece in column 2\n",
    "* ...\n",
    "* 7: Placing a game piece in column 7\n",
    "\n",
    "\n",
    "The state space is a matrix with 7 columns and 6 rows: \n",
    "* 0 means the cell is empty; \n",
    "* -1 means the cell is occupied by the yellow player; \n",
    "* 1 means the cell is occupied by the red player."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f879a",
   "metadata": {},
   "source": [
    "# 2. Play Games in the Connect Four Environment\n",
    "Next, we'll play games in the custom-made environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83ac2f",
   "metadata": {},
   "source": [
    "## 2.1. Play a full game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5af973",
   "metadata": {},
   "source": [
    "Here we'll play a full game, by randomly choosing an action from the action space each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f44d0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from utils.conn_env import conn\n",
    "\n",
    "# Initiate the game environment\n",
    "env = conn()\n",
    "state=env.reset()   \n",
    "env.render()   \n",
    "while True:\n",
    "    action = random.choice(env.validinputs)\n",
    "    time.sleep(1)\n",
    "    print(f\"Player red has chosen action={action}\")    \n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    print(f\"the current state is \\n{state.T[::-1]}\") \n",
    "    if done:\n",
    "        if reward==1:\n",
    "            print(f\"Player red has won!\") \n",
    "        else:\n",
    "            print(f\"It's a tie!\") \n",
    "        break   \n",
    "    action = random.choice(env.validinputs)\n",
    "    time.sleep(1)\n",
    "    print(f\"Player yellow has chosen action={action}\")    \n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    print(f\"the current state is \\n{state.T[::-1]}\") \n",
    "    if done:\n",
    "        if reward==-1:\n",
    "            print(f\"Player yellow has won!\") \n",
    "        else:\n",
    "            print(f\"It's a tie!\") \n",
    "        break\n",
    "env.close()            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791cedf2",
   "metadata": {},
   "source": [
    "Note that the outcome is different each time you run it because the actions are randomly chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064889bb",
   "metadata": {},
   "source": [
    "## 2.2. Play the Connect Four Game Manually\n",
    "Next, you’ll learn how to manually interact with the Connect Four game. You'll use the key board to enter a number between 1 and 7. The following lines of code show you how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac17214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter a number between 1 and 7\n",
      "the current state is \n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "Player red, what's your move?4\n",
      "Player red has chosen action=4\n",
      "the current state is \n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]]\n",
      "Player yellow has chosen action=5\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0]]\n",
      "Player red, what's your move?4\n",
      "Player red has chosen action=4\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0]]\n",
      "Player yellow has chosen action=7\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1 -1  0 -1]]\n",
      "Player red, what's your move?4\n",
      "Player red has chosen action=4\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1 -1  0 -1]]\n",
      "Player yellow has chosen action=3\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0 -1  1 -1  0 -1]]\n",
      "Player red, what's your move?4\n",
      "Player red has chosen action=4\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0 -1  1 -1  0 -1]]\n",
      "Player red has won!\n"
     ]
    }
   ],
   "source": [
    "env=conn()\n",
    "state=env.reset()   \n",
    "env.render()\n",
    "print('enter a number between 1 and 7')\n",
    "print(f\"the current state is \\n{state.T[::-1]}\")\n",
    "# Play a full game manually\n",
    "while True:   \n",
    "    action = int(input(\"enter your move:\"))\n",
    "    time.sleep(1)\n",
    "    print(f\"Player red has chosen action={action}\")    \n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    print(f\"the current state is \\n{state.T[::-1]}\")\n",
    "    if done:\n",
    "        if reward==1:\n",
    "            print(f\"Player red has won!\") \n",
    "        else:\n",
    "            print(f\"It's a tie!\") \n",
    "        break  \n",
    "    action = random.choice(env.validinputs)\n",
    "    time.sleep(1)\n",
    "    print(f\"Player yellow has chosen action={action}\")    \n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    print(f\"the current state is \\n{state.T[::-1]}\")\n",
    "    if done:\n",
    "        if reward==-1:\n",
    "            print(f\"Player yellow has won!\") \n",
    "        else:\n",
    "            print(f\"It's a tie!\") \n",
    "        break  \n",
    "env.close()      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fbca83",
   "metadata": {},
   "source": [
    "I am the red player, and I have won by connecting four pieces vertically in column 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcbdf00",
   "metadata": {},
   "source": [
    "# 3. Think One Step Ahead in Connect Four\n",
    "To think one step ahead in Connect Four, the AI player will iterate through all possible next moves and check if any one of them leads to a win right away. If yes, the AI player will take the move. Otherwise, the AI player randomly selects a move. \n",
    "\n",
    "We'll first code in such an AI player. We'll then test the efficacy of the game strategy by letting it play against random moves and see how often the AI player wins. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18df585",
   "metadata": {},
   "source": [
    "## 3.1. A Think-One-Step-Ahead AI \n",
    "To save space, we'll modulize most functions in this chapter and put them in the utils package of this book. Specifically, we define a function AI_think1() in the file ch03util.py in the folder /utils/. The function checks if there is a move that wins the game for the AI player right away. If yes, it returns the move. Otherwise, the function returns a value of None. The function is defined as follows. You can also download the file ch03util.py from the book's GitHub repository and put it in the folder /Desktop/utils/ on your computer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3557ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AI_think1(env):\n",
    "    for m in env.validinputs:\n",
    "        env_copy=deepcopy(env)\n",
    "        new_state, reward, done, info = env_copy.step(m) \n",
    "        if done and abs(reward)==1:\n",
    "            return m                  \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d70b06c",
   "metadata": {},
   "source": [
    "The function is the same as the one we defined in Chapter 2 for the Tic Tac Toe game. Both the red player and the yellow player can use this strategy to think one step ahead. Next, we'll play against the AI player and make sure it's working the way we intended it to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebaaecd",
   "metadata": {},
   "source": [
    "## 3.2. Manually Play against the AI Player\n",
    "To play against the AI players in this chapter, we define the AI_vs_manual(player_function) function in the local ch03util module in the local utils package. Specifically, we save the following function in the file ch03util.py in the /utils/ folder. If you have downloaded the file ch03util.py from the book's GitHub repository, the function is already defined in the file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9d23acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AI_vs_manual(env,player_function):\n",
    "    manual=input(\"Do you want to be red or yellow?\")\n",
    "    if manual.lower()==\"red\":\n",
    "        player=\"red\"\n",
    "    elif manual.lower()==\"yellow\":\n",
    "        player=\"yellow\"    \n",
    "    state=env.reset()\n",
    "    print(f\"the current state is state=\\n{state.T[::-1]}\")\n",
    "    # if you chose red, you move first\n",
    "    if player==\"red\":\n",
    "        move=input(\"enter your move:\")\n",
    "        state,reward,done,_=env.step(int(move))\n",
    "        print(f\"you have chosen move {move}\")    \n",
    "    while True:       \n",
    "        # AI moves\n",
    "        AI_move=player_function(env)\n",
    "        if AI_move==None:\n",
    "            AI_move=random.choice(env.validinputs)\n",
    "        state,reward,done,_=env.step(AI_move)\n",
    "        print(f\"AI has chosen move {AI_move}\")\n",
    "        print(f\"the current state is state=\\n{state.T[::-1]}\")\n",
    "        if done and reward!=0:\n",
    "            print(\"the AI player won\")\n",
    "            break\n",
    "        if done and reward==0:\n",
    "            print(\"game over; it's a tie\") \n",
    "            break               \n",
    "        move=input(\"enter your move:\")\n",
    "        state,reward,done,_=env.step(int(move))\n",
    "        print(f\"you have chosen move {move}\")\n",
    "        print(f\"the current state is state=\\n{state.T[::-1]}\")         \n",
    "        if done and reward!=0:\n",
    "            print(\"the human player won\")\n",
    "            break\n",
    "        if done and reward==0:\n",
    "            print(\"game over; it's a tie\")\n",
    "            break     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35e6969",
   "metadata": {},
   "source": [
    "The argument in the function, *player_function*, is a function name object in Python. Make sure that you don't put parentheses after AI_think1 when you put it inside the AI_vs_manual() as an argument and play against those AI players manually. \n",
    "\n",
    "The function first ask whether you want to be the red player or the yellow player. If you enter red, you'll play first. Otherwise, you'll play second. \n",
    "\n",
    "Below, we call the AI_vs_manual() function from the local package and put AI_think1 as the argment, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4c0d713",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to be the red or the yellow player?red\n",
      "the current state is state=\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "enter your move:1\n",
      "you have chosen move 1\n",
      "AI has chosen move 2\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 1 -1  0  0  0  0  0]]\n",
      "enter your move:1\n",
      "you have chosen move 1\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1 -1  0  0  0  0  0]]\n",
      "AI has chosen move 6\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1 -1  0  0  0 -1  0]]\n",
      "enter your move:7\n",
      "you have chosen move 7\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1 -1  0  0  0 -1  1]]\n",
      "AI has chosen move 7\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0 -1]\n",
      " [ 1 -1  0  0  0 -1  1]]\n",
      "enter your move:7\n",
      "you have chosen move 7\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 1  0  0  0  0  0 -1]\n",
      " [ 1 -1  0  0  0 -1  1]]\n",
      "AI has chosen move 7\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 -1]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 1  0  0  0  0  0 -1]\n",
      " [ 1 -1  0  0  0 -1  1]]\n",
      "enter your move:7\n",
      "you have chosen move 7\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 -1]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 1  0  0  0  0  0 -1]\n",
      " [ 1 -1  0  0  0 -1  1]]\n",
      "AI has chosen move 6\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 -1]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 1  0  0  0  0 -1 -1]\n",
      " [ 1 -1  0  0  0 -1  1]]\n",
      "enter your move:7\n",
      "you have chosen move 7\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 -1]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 1  0  0  0  0 -1 -1]\n",
      " [ 1 -1  0  0  0 -1  1]]\n",
      "AI has chosen move 2\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 -1]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 1 -1  0  0  0 -1 -1]\n",
      " [ 1 -1  0  0  0 -1  1]]\n",
      "enter your move:1\n",
      "you have chosen move 1\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 -1]\n",
      " [ 1  0  0  0  0  0  1]\n",
      " [ 1 -1  0  0  0 -1 -1]\n",
      " [ 1 -1  0  0  0 -1  1]]\n",
      "AI has chosen move 3\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 -1]\n",
      " [ 1  0  0  0  0  0  1]\n",
      " [ 1 -1  0  0  0 -1 -1]\n",
      " [ 1 -1 -1  0  0 -1  1]]\n",
      "enter your move:2\n",
      "you have chosen move 2\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 -1]\n",
      " [ 1  1  0  0  0  0  1]\n",
      " [ 1 -1  0  0  0 -1 -1]\n",
      " [ 1 -1 -1  0  0 -1  1]]\n",
      "AI has chosen move 1\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [-1  0  0  0  0  0 -1]\n",
      " [ 1  1  0  0  0  0  1]\n",
      " [ 1 -1  0  0  0 -1 -1]\n",
      " [ 1 -1 -1  0  0 -1  1]]\n",
      "enter your move:1\n",
      "you have chosen move 1\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  1]\n",
      " [ 1  0  0  0  0  0  1]\n",
      " [-1  0  0  0  0  0 -1]\n",
      " [ 1  1  0  0  0  0  1]\n",
      " [ 1 -1  0  0  0 -1 -1]\n",
      " [ 1 -1 -1  0  0 -1  1]]\n",
      "AI has chosen move 5\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  1]\n",
      " [ 1  0  0  0  0  0  1]\n",
      " [-1  0  0  0  0  0 -1]\n",
      " [ 1  1  0  0  0  0  1]\n",
      " [ 1 -1  0  0  0 -1 -1]\n",
      " [ 1 -1 -1  0 -1 -1  1]]\n",
      "enter your move:1\n",
      "you have chosen move 1\n",
      "the current state is state=\n",
      "[[ 1  0  0  0  0  0  1]\n",
      " [ 1  0  0  0  0  0  1]\n",
      " [-1  0  0  0  0  0 -1]\n",
      " [ 1  1  0  0  0  0  1]\n",
      " [ 1 -1  0  0  0 -1 -1]\n",
      " [ 1 -1 -1  0 -1 -1  1]]\n",
      "AI has chosen move 4\n",
      "the current state is state=\n",
      "[[ 1  0  0  0  0  0  1]\n",
      " [ 1  0  0  0  0  0  1]\n",
      " [-1  0  0  0  0  0 -1]\n",
      " [ 1  1  0  0  0  0  1]\n",
      " [ 1 -1  0  0  0 -1 -1]\n",
      " [ 1 -1 -1 -1 -1 -1  1]]\n",
      "the AI player won\n"
     ]
    }
   ],
   "source": [
    "from utils.ch03util import AI_vs_manual, AI_think1\n",
    "\n",
    "env=conn()\n",
    "AI_vs_manual(env,AI_think1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79eb29",
   "metadata": {},
   "source": [
    "As you can see above, the AI player takes the winning move 5 and wins the game. This shows that the AI player will take a move if the move leads to a win right away.\n",
    "\n",
    "As an exercise, you can call the AI_vs_manual() and use AI_think1 as its argument and play game with the AI player. Choose yellow at the beginning so that the AI player goes first. Create a chance for the AI to win and see if the AI player takes the winning move right away. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19f616",
   "metadata": {},
   "source": [
    "## 3.3. How Good Is the Think-One-Step-Ahead AI?\n",
    "Below, we'll define a function to simulate a game between two players, player 1 and player 2. The function returns the result of the game: 1 if player 1 wins, -1 if player 2 wins, and 0 if it's a tie. We save the game in the file ch03util.py in the /utils/ folder. If you have downloaded the file ch03util.py from the book's GitHub repository, the function is already defined in the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d70be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_game(player1,player2):   \n",
    "    env.reset()   \n",
    "    while True:       \n",
    "        move=player1(env)\n",
    "        if move==None:\n",
    "            move=random.choice(env.validinputs)\n",
    "        state,reward,done,_=env.step(move)\n",
    "        if done:\n",
    "            return reward            \n",
    "        move=player2(env)\n",
    "        if move==None:\n",
    "            move=random.choice(env.validinputs)\n",
    "        state,reward,done,_=env.step(move)\n",
    "        if done:\n",
    "            return reward "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da6db75",
   "metadata": {},
   "source": [
    "Since we'll let the AI player play against a player who makes random moves, we'll also define a random_player() function in the file ch03util.py in the /utils/ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "643bd004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_player(env):               \n",
    "    return random.choice(env.validinputs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a86877f",
   "metadata": {},
   "source": [
    "We create a list *results* to store game outcomes. We simulate 1000 games and half the time, the AI player moves first and the other half, the random player moves first. This way, no player has a first-mover advantage and we have a fair assessment of the power of the AI player against the random player. Whenever the AI player moves second, we multiple the outcome by -1 so that a value 1 in the list *results* indicates that the AI player has won and the random player has lost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "176c2b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ch03util import test_game, AI_think1, random_player\n",
    "\n",
    "env=conn()\n",
    "results=[]\n",
    "for i in range(1000):\n",
    "    # AI moves first if i is an even number\n",
    "    if i%2==0:\n",
    "        result=test_game(env,AI_think1,random_player)\n",
    "        # record game outcome\n",
    "        results.append(result)\n",
    "    # AI moves second if i is an odd number\n",
    "    else:\n",
    "        result=test_game(env,random_player,AI_think1)\n",
    "        # record negative of game outcome\n",
    "        results.append(-result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620495b9",
   "metadata": {},
   "source": [
    "We iterate i from 0 to 999. Whenever i is an even number, we simulate a game and let the AI player move first. The outcome is added to the list *results*: 1 means the first player (the AI player in this case) wins and -1 means the second player wins. Whenever i is an odd number, we simulate a game and let the random player move first. We then multiply the outcome by -1 so that 1 means the AI player has won. \n",
    "\n",
    "Run the above code cells so that we simulate 1000 games and get the outcome.\n",
    "\n",
    "Next, we count how many times the AI player has won by counting the number of 1s in the list *results*. Similarly, the number of -1s is the number of times the AI player has lost. Like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1e19a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the AI player has won 768 games\n",
      "the AI player has lost 232 games\n",
      "the game has tied 0 games\n"
     ]
    }
   ],
   "source": [
    "# count how many times AI player has won\n",
    "wins=results.count(1)\n",
    "print(f\"the AI player has won {wins} games\")\n",
    "# count how many times AI player has lost\n",
    "losses=results.count(-1)\n",
    "print(f\"the AI player has lost {losses} games\")\n",
    "# count tie games\n",
    "ties=results.count(0)\n",
    "print(f\"the game has tied {ties} games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a18db0a",
   "metadata": {},
   "source": [
    "Results show that the AI player has won 768 out of the 1000 games; it has lost to the random player 232 times. There is no tie game. This indicates that the think-one-step-ahead AI player is clearly better than a random player. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7373bfa",
   "metadata": {},
   "source": [
    "# 4. Think Two Steps Ahead\n",
    "\n",
    "Thinking two steps ahead in Connect Four is more complicated than that in Tic Tac Toe. While in some cases, the AI player needs to block a move to prevent the opponent from winning in two steps, in other cases, the AI player needs to avoid certain moves to achieve that goal. We’ll separate these two cases. Let’s first use two examples to demonstrate the two cases."
   ]
  },
  {
   "attachments": {
    "toavoid.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtgAAAKqCAYAAAAAOSnPAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAD3nSURBVHhe7d0xjxxpXj/wmkMIaSUkEAEkZJ4LlnsF9iuwT6CLTv/sMhuJwE4uu/CyTeyMdbZku9ERnP0K7FdwOiRmMoIlAVYEQICYf1dPtd3jbc9Ot596nu9T9flIpetdlq6p37ef7m9X1/Scfffdd1cDAABQxI+m/wUAAApQsAEAoKB3l4h8/fXX238BAAAc56//+q+Hzz77bHv7RsF+8uTJ9l8CAAB3c3V1NXz77bcfL9jjfwAAANzdfsF2DTYAABSkYAMAQEEKNgAAFKRgAwBAQQo2AAAUpGADAEBBCjYAABSkYAMAQEEKNgAAFKRgAwBAQQo2AAAUpGDfyeXw4sHZcHb2ZHg9/RsqurwcXr94MjzYZvB+e/Bgk8fl9N9Q1eXrD/N4MDx48nqMigSXL4YHUy4vZFLV5YsHe+viI9tmrVDR5evhxZPNc9R+Bg8eDE82LyCWRx2vn+zN/i7bAtaIgn0Hly9+MTx7O/0DdY1F7vx8ePTs5fD2gwzevn05PDrfFG0NoqLrN5vnjz7M4+3w9uWj4fxcoWtvk9Evnm0SoYWL35t8ku3JgPNHw7OXm+eo6d9tbZ7AXj46H84fvFCymYWC/QPGsxHn2nUb41m4sciNt+8/Hl5dXAxXV1fX28Wr4fn97X81vH12PjghVMfrJ+fTm837w+NXN/N4vM3j7fDs3Cc9LTkh0NLr4Tcvx/+9Pzy/mNbGoe3Lh9v/mpltyvX2ZMB4e/sassvgYnj1/gVkOPcCMruHX+49/j+yvXo8/cfDJqsFrBEF+6MuN2tTuW7p8rffTGccNovtzZfDw3v3tv+0de/h8PTNxbuS/fLXzkLMbvOG59fb8rBJ5NWb4cuHN/P48s2mZG//4eXwa6ex29hk9AvPWe1c/vPwu/F/7/98+One8qCFy+HF7gnr/vPhYvsacv2Pmyes4eHTN8PFuxeQ3zgp0NrmzdDmvdDW41ebrK5vdk3BPuDy9YvhyYPzTdjXL1T370+LkIouh99+MxWFxz/7yGK7Nzz91fSW9+03w291ulntv+H52cFAHg4/28Xx+4vrG1T0/tKQx4/fnQqipovfX6+Rn/x48+xEU6+/ePdp2/Ovnh7M495Pf775v45eDr/RsBt6PTx5366HpXzAo2B/z+vhi0fPhutuff0x+Jtf/WT7f6GmTXl+M310dNtqO/98eoJkbveevpk+ylvG2YWleXdpyPgC9bPrf0ddl/+8PX89PD78DpSKXl9fq3P7pwn3ng5vpssTXLXTzusnjzZvcUabN0O/XE4QCvZH3N+8SF1cffAxOHl2Z4xob/8SEgWjrneXhizj2sVeXf+C4+Ph8/Pvf2vF9bce+Zitjstheq+z6dc/9WlCsr3XjfvPvxqeLigsBft7Hg6/vLga3mxepCzKfO/OUgw/GX4ssGbGy6oenE/fXHH/+bCgkxAd2Ls0ZCHXLvZp9wuOL4dnB7614vpbj85961EVF8Puy1x+sn1huPz+V4tOX9NHW6+/2H3j0ePhV0tq1xsK9gH7v0tHsL13vh+/Tpv5XH9l3/hidf7o+kny/vNXw8Wbw9c7Mo8bl4ZYBO3sfsFx6/7weFwL0+UHVxcXw6vrr9nZfuuRkj2zG1mMz1Pn3/9q0elr+s58TV9DuzelGwt8DVew6dT7s3bjO18fi7cwniW6v/0l4N118G+fPRp+8cQLVjUuDcmxd7na9lt2nu59Cnrv3vDwyzfvvobs7bMvfGtFJWOJHpfI9WWf0xue8Wv6pjc8vqavncsXv17ktdc7CjYduj4jse0VGz4Wb+Xh8OXVm+HNm822edG6ePV8W7Tfvty8YDkrVMH7N5nWQICHX07l7eO/MPfwS19l2cL95xcfXPZ5/Ybn/df0/dofyKpu75vCFvq1lgo2nblZrscnTifuMtx7+HR48/4U3fCFk0KzcmlIj86Hz3cnTn2VZR33nw9ffeTa3ntPfzW94Xk7fON7Xuu6/O3w7pt4f7XMywoVbDry/XL9ZmG/FNG9h798/8d/fLHsfFwa0ql7w49962tdt34nuTc8rfzw31Xon4JNJ15v//jP+8tClOtMCkQN71+cXg6Pdt+KsL/t/mjD5r96dj79O9eZshb3fjzsnobuf34+3TrE81Ub+5eHfL55m7NMCjb5Ljfl+uzR3h//Ga9xVK4zvf/+WeBDe9/PfGvx49Pc9cy056s23n+N4pK/p1zBJtymXJ/v/ZWni/GP/2z/gcpeP5nOhN76C4x7T5wKxGze/1XNj2y7a+G3a2b6dxbOrO60PvauO73+fmbmcW/46c/fXat2yze2eL5qYu9rFJe8DhRsgo3XXN8s164Kaefhz374Fxj3/+Ttz5f4a+HwEe/XxzfD4d+Xe/+tL+Mv3vljTPO699Ofb56FRi+HRx+5POr989Xy/shJtHdfaXl/WPL7GgWbWO++JWFj/F5Zz3+N7f8C46Prv4L2rkdcbsrDkwfD7tLfpf3JW/hB79bHeN37B38lcLzMbf93SBb6rQlR7j0dvnr/hDU8GL+f//0T1qZc7z9f/dLXXFZ0+e66nGX/BWYFm1Cvhy92r0YbLx9NH7/esvnraHO7Nzx982q4/vsM138F7Xw3//NNebi+SN63u7BSm/Xx1c318e75abzMbbs8xt8h8dWitYyXUr37C5rj9/PvfuH37HxTrqfnq8evPF9VdvH+upzF/oLjSMEm040/dUuOh8OXby6Gi1ePh/vTyaFr9zcvVM+HVxdXXqxYr3vX6+PV84+tj/F3SKyPmrZ/UOZifONzI5BNPo+H5+O3UXm3086tX6HYv7Pvvvvuarzx9ddfD0+ePNn+MgwAAHB333777fDZZ59tbzuDDQAABSnYAABQkIINAAAFffI12ONv5AIAwBp8rCsXuwZbuQYAYE3u0n9dIgIAAAUp2AAAUJCCDQAABc1QsMcLv202m81ms9lstiVsx3MGGwAAClKwAQCgIAUbAAAKUrABAKAgBRsAAApSsAEAoCAFGwAAClpVwb66+vSNcg7N99iNcg7N99iNcg7N99iNcg7N99iNcg7N99iNcg7N99htaRZfsEuHV/r+1qb0/Erf39qUnl/p+1ub0vMrfX9rU3p+pe9vbUrPr/T9rU3p+ZW+v9YWWbBrhVRrP72rNada++ldrTnV2k/vas2p1n56V2tOtfbTu1pzqrWf3tWaU639zGkxBbt1GK33n6b1PFrvP03rebTef5rW82i9/zSt59F6/2laz6P1/tO0nkfr/Z9qEQU7bei9PQhKk0cWeWSRRxZ5ZJFHFnmcruuCPQ46ddjJP9tc5JFFHlnkkUUeWeSRRR6frsuC3ctwRz39rKeSRxZ5ZJFHFnlkkUcWeZTTXcHu9cHd68/9Q+SRRR5Z5JFFHlnkkUUeZXVVsHt/UC9tUcojizyyyCOLPLLII4s8yuuiYI+DW8qDeQnHIo8s8sgijyzyyCKPLPKYT3zBXkrwH+r1uOSRRR5Z5JFFHlnkkUUe84ou2EsNf6e345NHFnlkkUcWeWSRRxZ5zC+2YC89/J1ejlMeWeSRRR5Z5JFFHlnkUUdkwV5L+DvpxyuPLPLIIo8s8sgijyzyqKeLX3IEAIBexBXstb272kk9bnlkkUcWeWSRRxZ5ZJFHXVEFe63h76QdvzymGyHkMd0IIY/pRgh5TDdCyGO6EUIe042KYgr22sPfSZmDPK7JI4s8ssgjizyyyCNL7Tm4BhsAAAqKKNjeXd3Ueh7yuEkeWeSRRR5Z5JFFHllqzsMZbAAAKKh5wfbu6rBWc5HHYfLIIo8s8sgijyzyyFJrLk0LtvBvV3s+8ridPLLII4s8ssgjizyy1JiPS0QAAKAgBRsAAApqVrB9fHE3teYkj7uRRxZ5ZJFHFnlkkUeWuefkDDYAABSkYAMAQEFNCraPL44z97zkcRx5ZJFHFnlkkUcWeWSZc17OYAMAQEEKNgAAFFS9YPv44jRzzU0ep5FHFnlkkUcWeWSRR5a55uYMNgAAFKRgAwBAQQo2AAAUpGADAEBBCjYAABSkYAMAQEEKNgAAFKRgAwBAQQo2AAAUpGADAEBBCjYAABSkYAMAQEEKNgAAFKRgAwBAQQo2AAAUpGADAEBB1Qv22dl0g6PMNTd5nEYeWeSRRR5Z5JFFHlnmmpsz2AAAUJCCDQAABTUp2D7GOM7c85LHceSRRR5Z5JFFHlnkkWXOeTmDDQAABSnYAABQULOC7WOMu6k1J3ncjTyyyCOLPLLII4s8ssw9J2ewAQCgIAUbAAAKalqwfYxxu9rzkcft5JFFHlnkkUUeWeSRpcZ8mp/B9iA4rNVc5HGYPLLII4s8ssgjizyy1JqLS0QAAKCgiILtXdZNrechj5vkkUUeWeSRRR5Z5JGl5jycwQYAgIJiCrZ3WddS5iCPa/LIIo8s8sgijyzyyFJ7DlFnsNf+IEg7fnlMN0LIY7oRQh7TjRDymG6EkMd0I4Q8phsVxV0istYHQepxyyOLPLLII4s8ssgjizzqcg02AAAUFFmw1/YuK/145ZFFHlnkkUUeWeSRRR71xJ7BXsuDoJfjlEcWeWSRRxZ5ZJFHFnnUEX2JyNIfBL0dnzyyyCOLPLLII4s8sshjfvHXYC/1QdDrcckjizyyyCOLPLLII4s85tXFLzmOw1rKA2EJxyKPLPLIIo8s8sgijyzymE8XBXtnCQ/kJZFHFnlkkUcWeWSRRxZ5lNdVwR71+iBY2mLckUcWeWSRRxZ5ZJFHFnmU1V3BHo3D7OWB0NPPeip5ZJFHFnlkkUcWeWSRRzldFuyd5OGmBz8HeWSRRxZ5ZJFHFnlkkcen67pg76QNuofg5ySPLPLIIo8s8sgijyzyON0iCvZoHPpua6H1/tO0nkfr/adpPY/W+0/Teh6t95+m9Txa7z9N63m03n+a1vNovf9TLaZg76sVRq399K7WnGrtp3e15lRrP72rNada++ldrTnV2k/vas2p1n56V2tOtfYzp0UW7H2lQyp9f2tTen6l729tSs+v9P2tTen5lb6/tSk9v9L3tzal51f6/tam9PxK319riy/Y+/bDO3WjnEPzPXajnEPzPXajnEPzPXajnEPzPXajnEPzPXajnEPzPXZbmlUVbAAAmJuCDQAABSnYAABQkIINAAAFKdgAAFCQgg0AAAUp2AAAUJCCDQAABSnYAABQkIINAAAFKdgAAFCQgg0AAAUp2AAAUJCCDQAABSnYAABQkIINAAAFKdgAAFCQgg0AAAUp2AAAUJCCDQAABa2qYF9dffpGOYfme+xGOYfme+xGOYfme+xGOYfme+xGOYfme+xGOYfme+y2NIsv2KXDK31/a1N6fqXvb21Kz6/0/a1N6fmVvr+1KT2/0ve3NqXnV/r+1qb0/ErfX2uLLNi1Qqq1n97VmlOt/fSu1pxq7ad3teZUaz+9qzWnWvvpXa051dpP72rNqdZ+5rSYgt06jNb7T9N6Hq33n6b1PFrvP03rebTef5rW82i9/zSt59F6/2laz6P1/k+1iIKdNvTeHgSlySOLPLLII4s8ssgjizxO13XBHgedOuzkn20u8sgijyzyyCKPLPLIIo9P12XB7mW4o55+1lPJI4s8ssgjizyyyCOLPMrprmD3+uDu9ef+IfLIIo8s8sgijyzyyCKPsroq2L0/qJe2KOWRRR5Z5JFFHlnkkUUe5XVRsMfBLeXBvIRjkUcWeWSRRxZ5ZJFHFnnMJ75gLyX4D/V6XPLIIo8s8sgijyzyyCKPeUUX7KWGv9Pb8ckjizyyyCOLPLLII4s85hdbsJce/k4vxymPLPLIIo8s8sgijyzyqCOyYK8l/J3045VHFnlkkUcWeWSRRxZ51NPFLzkCAEAv4gr22t5d7aQetzyyyCOLPLLII4s8ssijrqiCvdbwd9KOXx7TjRDymG6EkMd0I4Q8phsh5DHdCCGP6UZFMQV77eHvpMxBHtfkkUUeWeSRRR5Z5JGl9hxcgw0AAAVFFGzvrm5qPQ953CSPLPLIIo8s8sgijyw15+EMNgAAFNS8YHt3dVirucjjMHlkkUcWeWSRRxZ5ZKk1l6YFW/i3qz0fedxOHlnkkUUeWeSRRR5ZaszHJSIAAFCQgg0AAAU1K9g+vribWnOSx93II4s8ssgjizyyyCPL3HNyBhsAAApSsAEAoKAmBdvHF8eZe17yOI48ssgjizyyyCOLPLLMOS9nsAEAoCAFGwAACqpesH18cZq55iaP08gjizyyyCOLPLLII8tcc3MGGwAAClKwAQCgIAUbAAAKUrABAKAgBRsAAApSsAEAoCAFGwAAClKwAQCgIAUbAAAKUrABAKAgBRsAAApSsAEAoCAFGwAAClKwAQCgIAUbAAAKUrABAKCg6gX77Gy6wVHmmps8TiOPLPLIIo8s8sgijyxzzc0ZbAAAKEjBBgCAgpoUbB9jHGfuecnjOPLIIo8s8sgijyzyyDLnvJzBBgCAghRsAAAoqFnB9jHG3dSakzzuRh5Z5JFFHlnkkUUeWeaekzPYAABQkIINAAAFNS3YPsa4Xe35yON28sgijyzyyCKPLPLIUmM+zc9gexAc1mou8jhMHlnkkUUeWeSRRR5Zas3FJSIAAFBQRMH2Luum1vOQx03yyCKPLPLIIo8s8shScx7OYAMAQEExBdu7rGspc5DHNXlkkUcWeWSRRxZ5ZKk9h6gz2Gt/EKQdvzymGyHkMd0IIY/pRgh5TDdCyGO6EUIe042K4i4RWeuDIPW45ZFFHlnkkUUeWeSRRR51uQYbAAAKiizYa3uXlX688sgijyzyyCKPLPLIIo96Ys9gr+VB0MtxyiOLPLLII4s8ssgjizzqiL5EZOkPgt6OTx5Z5JFFHlnkkUUeWeQxv/hrsJf6IOj1uOSRRR5Z5JFFHlnkkUUe8+rilxzHYS3lgbCEY5FHFnlkkUcWeWSRRxZ5zKeLgr2zhAfyksgjizyyyCOLPLLII4s8yuuqYI96fRAsbTHuyCOLPLLII4s8ssgjizzK6q5gj8Zh9vJA6OlnPZU8ssgjizyyyCOLPLLIo5wuC/ZO8nDTg5+DPLLII4s8ssgjizyyyOPTdV2wd9IG3UPwc5JHFnlkkUcWeWSRRxZ5nG4RBXs0Dn23tdB6/2laz6P1/tO0nkfr/adpPY/W+0/Teh6t95+m9Txa7z9N63m03v+pFlOw99UKo9Z+eldrTrX207tac6q1n97VmlOt/fSu1pxq7ad3teZUaz+9qzWnWvuZ0yIL9r7SIZW+v7UpPb/S97c2pedX+v7WpvT8St/f2pSeX+n7W5vS8yt9f2tTen6l76+1xRfsffvhnbpRzqH5HrtRzqH5HrtRzqH5HrtRzqH5HrtRzqH5HrtRzqH5HrstzaoKNgAAzE3BBgCAghRsAAAoSMEGAICCFGwAAChIwQYAgIIUbAAAKEjBBgCAghRsAAAoSMEGAICCFGwAAChIwQYAgIIUbAAAKEjBBgCAghRsAAAoSMEGAICCFGwAAChIwQYAgIIUbAAAKEjBBgCAglZVsK+uPn2jnKvh7JM3yjn0eD92o5xD8z12o5xD8z12o5xD8z12o5xD8z12W5rFF+zS4ZW+v7UpXY5L39/alH48l76/tSk9v9L3tzal51f6/tam9PxK39/alJ5f6ftrbZEFu1ZItfbTu1oluNZ+elfrcVtrP72rNada++ldrTnV2k/vas2p1n56V2tOtfYzp8UU7NZhtN5/mtZlt/X+07R+fLbef5rW82i9/zSt59F6/2laz6P1/tO0nkfr/Z9qEQU7bei9PQhKSyu1ay/Z1kcWeWSRRxZ5ZJHH6bou2OOgU4ed/LPNJfmMcfLPNhfrI4s8ssgjizyyyOPTdVmwexnuqKef9VQ9ldc1FG3rI4s8ssgjizyyyKOc7gp2rw/uXn/uH9JrWV1qybY+ssgjizyyyCOLPMrqqmD3/qBe2qLsvaQurWRbH1nkkUUeWeSRRR7ldVGwx8Et5cG8hGMZi+lSyukSjsX6yCKPLPLIIo8s8phPfMFeSvAf6vW4lnbWd6fX47I+ssgjizyyyCOLPOYVXbCXGv5Ob8e31HK909vxWR9Z5JFFHlnkkUUe84st2EsPf6eX41x6ud7p5TitjyzyyCKPLPLIIo86Igv2WsLfST/etZTrnfTjtT6yyCOLPLLII4s86unilxwBAKAXcQV7be+udlKPe21nr3dSj9v6yCKPLPLIIo8s8qgrqmCvNfydtONfa7neSTt+62O6EUIe040Q8phuhJDHdCOEPKYbFcUU7LWHv5Myh7WX652UOVgf12LWhzy25JFFHlnkkaX2HFyDDQAABUUUbO+ubmo9D2evb2o9D+vjpubrQx43yCOLPLLII0vNeTiDDQAABTUv2N5dHdZqLs5eH9ZqLtbHYc3WhzwOkkcWeWSRR5Zac2lasIV/u9rzUa5vV3s+1sftqq8PedxKHlnkkUUeWWrMxyUiAABQkIINAAAFNSvYPr64m1pzcnnI3dSak/VxN9XWhzzuRB5Z5JFFHlnmnpMz2AAAUJCCDQAABTUp2D6+OM7c83J5yHHmnpf1cZzZ14c8jiKPLPLIIo8sc87LGWwAAChIwQYAgIKqF2wfX5xmrrm5POQ0c83N+jjNbOtDHieRRxZ5ZJFHlrnm5gw2AAAUpGADAEBBCjYAABSkYAMAQEEKNgAAFKRgAwBAQQo2AAAUpGADAEBBCjYAABSkYAMAQEEKNgAAFKRgAwBAQQo2AAAUpGADAEBBCjYAABSkYAMAQEHVC/bZ2XSDo8w1t7PharrFMeaam/VxmtnWhzxOIo8s8sgijyxzzc0ZbAAAKEjBBgCAgpoUbB9jHGfueblM5Dhzz8v6OM7s60MeR5FHFnlkkUeWOeflDDYAABSkYAMAQEHNCraPMe6m1pxcJnI3teZkfdxNtfUhjzuRRxZ5ZJFHlrnn5Aw2AAAUpGADAEBBTQu2jzFuV3s+LhO5Xe35WB+3q74+5HEreWSRRxZ5ZKkxn+ZnsD0IDms1FyX7sFZzsT4Oa7Y+5HGQPLLII4s8stSai0tEAACgoIiC7V3WTa3n4Sz2Ta3nYX3c1Hx9yOMGeWSRRxZ5ZKk5D2ewAQCgoJiC7V3WtZQ5OIt9LWUO1se1mPUhjy15ZJFHFnlkqT2HqDPYa38QpB3/2kt22vFbH9ONEPKYboSQx3QjhDymGyHkMd2oKO4SkbU+CFKPe60lO/W4rY8s8sgijyzyyCKPulyDDQAABUUW7LW9y0o/3rWdxU4/XusjizyyyCOLPLLIo57YM9hreRD0cpxrKdm9HKf1kUUeWeSRRR5Z5FFH9CUiS38Q9HZ8Sy/ZvR2f9ZFFHlnkkUUeWeQxv/hrsJf6IOj1uJZasns9LusjizyyyCOLPLLIY15d/JLjOKylPBCWcCxjGV1K0V7CsVgfWeSRRR5Z5JFFHvPpomDvLOGBvCTdF9OFvEnYsT6yyCOLPLLII4s8yuuqYI96fRAsbTHu9FpSl1aud6yPLPLIIo8s8sgij7K6K9ijcZi9PBB6+llPNZbVXgprTz/rqayPLPLIIo8s8sgij3K6LNg7ycNND34OyeV1DcX6Q9ZHFnlkkUcWeWSRx6frumDvpA26h+DnlFZk11asP2R9ZJFHFnlkkUcWeZxuEQV7NA59t7XQev9pdmeMW5Xb1vtP0/rx2Xr/aVrPo/X+07SeR+v9p2k9j9b7T9N6Hq33f6rFFOx9tcKotZ/e1Sq7tfbTu1qP21r76V2tOdXaT+9qzanWfnpXa0619tO7WnOqtZ85LbJg7ysdUun7W5vSJbj0/a1N6cdz6ftbm9LzK31/a1N6fqXvb21Kz6/0/a1N6fmVvr/WFl+w9+2Hd+pGOfvl+NSNcg493o/dKOfQfI/dKOfQfI/dKOfQfI/dKOfQfI/dlmZVBRsAAOamYAMAQEEKNgAAFKRgAwBAQQo2AAAUpGADAEBBCjYAABSkYAMAQEEKNgAAFKRgAwBAQQo2AAAUpGADAEBBCjYAABSkYAMAQEEKNgAAFKRgAwBAQQo2AAAUpGADAEBBCjYAABSkYAMAQEGrKthXV5++Uc7V1dknb5Rz6PF+7EY5h+Z77EY5h+Z77EY5h+Z77EY5h+Z77LY0iy/YpcMrfX9rU7ocl76/tSn9eC59f2tTen6l729tSs+v9P2tTen5lb6/tSk9v9L319oiC3atkGrtp3e1SnCt/fSu1uO21n56V2tOtfbTu1pzqrWf3tWaU6399K7WnGrtZ06LKditw2i9/zSty27r/adp/fhsvf80refRev9pWs+j9f7TtJ5H6/2naT2P1vs/1SIKdtrQe3sQlJZWatdesq2PLPLIIo8s8sgij9N1XbDHQacOO/lnm0vyGePkn20u1kcWeWSRRxZ5ZJHHp+uyYPcy3FFPP+upeiqvayja1kcWeWSRRxZ5ZJFHOd0V7F4f3L3+3D+k17K61JJtfWSRRxZ5ZJFHFnmU1VXB7v1BvbRF2XtJXVrJtj6yyCOLPLLII4s8yuuiYI+DW8qDeQnHMhbTpZTTJRyL9ZFFHlnkkUUeWeQxn/iCvZTgP9TrcS3trO9Or8dlfWSRRxZ5ZJFHFnnMK7pgLzX8nd6Ob6nleqe347M+ssgjizyyyCOLPOYXW7CXHv5OL8e59HK908txWh9Z5JFFHlnkkUUedUQW7LWEv5N+vGsp1zvpx2t9ZJFHFnlkkUcWedTTxS85AgBAL+IK9treXe2kHvfazl7vpB639ZFFHlnkkUUeWeRRV1TBXmv4O2nHv9ZyvZN2/NbHdCOEPKYbIeQx3Qghj+lGCHlMNyqKKdhrD38nZQ5rL9c7KXOwPq7lrI/pxsrJI4s8ssgjS+05uAYbAAAKiijY3l3d1Hoezl7f1Hoe1sdN7dfHdIMteWSRRxZ5ZKk5D2ewAQCgoOYF27urw1rNxdnrw1rNxfo4rN36mG5wgzyyyCOLPLLUmkvTgi3829Wej3J9u9rzsT5uV399TDc4SB5Z5JFFHllqzMclIgAAUJCCDQAABTUr2D6+uJtac3J5yN3UmpP1cTf11sd0g1vJI4s8ssgjy9xzcgYbAAAKUrABAKCgJgXbxxfHmXteLg85ztzzsj6OM//6mG5wJ/LIIo8s8sgy57ycwQYAgIIUbAAAKKh6wfbxxWnmmpvLQ04z19ysj9PMtz6mGxxFHlnkkUUeWeaamzPYAABQkIINAAAFKdgAAFCQgg0AAAUp2AAAUJCCDQAABSnYAABQkIINAAAFKdgAAFCQgg0AAAUp2AAAUJCCDQAABSnYAABQkIINAAAFKdgAAFCQgg0AAAVVL9hnZ9MNjjLX3M7OrqZbHGOuuVkfp5lvfUw3OIo8ssgjizyyzDU3Z7ABAKAgBRsAAApqUrB9jHGcueflMpHjzD0v6+M486+P6QZ3Io8s8sgijyxzzssZbAAAKEjBBgCAgpoVbB9j3E2tOblM5G5qzcn6uJt662O6wa3kkUUeWeSRZe45OYMNAAAFKdgAAFBQ04LtY4zb1Z6Py0RuV3s+1sft6q+P6QYHySOLPLLII0uN+TQ/g+1BcFiruSjZh7Wai/VxWLv1Md3gBnlkkUcWeWSpNReXiAAAQEERBdu7rJtaz8NZ7Jtaz8P6uKn9+phusCWPLPLIIo8sNefhDDYAABQUU7C9y7qWMgdnsa+lzMH6uJazPqYbKyePLPLIIo8stecQdQZ77Q+CtONfe8lOO37rY7oRQh7TjRDymG6EkMd0I4Q8phsVxV0istYHQepxr7Vkpx639ZFFHlnkkUUeWeRRl2uwAQCgoMiCvbZ3WenHu7az2OnHa31kkUcWeWSRRxZ51BN7BnstD4JejnMtJbuX47Q+ssgjizyyyCOLPOqIvkRk6Q+C3o5v6SW7t+OzPrLII4s8ssgjizzmF38N9lIfBL0e11JLdq/HZX1kkUcWeWSRRxZ5zKuLX3Ich7WUB8ISjmUso0sp2ks4FusjizyyyCOLPLLIYz5dFOydJTyQl6T/Yrqss/HWRxZ5ZJFHFnlkkUd5XRXsUa8PgqUtxp1eS+rSyvWO9ZFFHlnkkUUeWeRRVncFezQOs5cHQk8/66nGstpLYe3pZz2V9ZFFHlnkkUUeWeRRTpcFeyd5uOnBzyG5vK6hWH/I+sgijyzyyCKPLPL4dF0X7J20QfcQ/JzSiuzaivWHrI8s8sgijyzyyCKP0y2iYI/Goe+2FlrvP83ujHGrctt6/2laPz5b7z9N63m03n+a1vNovf80refRev9pWs+j9f5PtZiCva9WGLX207taZbfWfnpX63Fbaz+9qzWnWvvpXa051dpP72rNqdZ+eldrTrX2M6dFFux9pUMqfX9rU7oEl76/tSn9eC59f2tTen6l729tSs+v9P2tTen5lb6/tSk9v9L319riC/a+/fBO3ShnvxyfulHOocf7sRvlHJrvsRvlHJrvsRvlHJrvsRvlHJrvsdvSrKpgAwDA3BRsAAAoSMEGAICCFGwAAChIwQYAgIIUbAAAKEjBBgCAghRsAAAoSMEGAICCFGwAAChIwQYAgIIUbAAAKEjBBgCAghRsAAAoSMEGAICCFGwAAChIwQYAgIIUbAAAKEjBBgCAghRsAAAoaFUF+2o4++SNcq6uNjP9xI1yDs332I1yrq4+faOcQ/M9dqOcQ/M9dqOcQ/M9dluaxRfs0uW49P2tTekyVvr+1qb0/Erf39qUfrEpfX9rU3p+pe9vbUrPr/T9rU3p+ZW+v9YWWbBrleBa++ldrdJVaz+9qzWnWvvpXa0XlVr76V2tOdXaT+9qzanWfnpXa0619jOnxRTs1mW39f7TtC5XrfefpvU8Wu8/TesXj9b7T9N6Hq33n6b1PFrvP03rebTe/6kWUbDTSu3aS3ZaiVp7qZNHlrQXid5etEqTRxZ5ZJHH6bou2MlnjJN/trmMxSm1PCX/bHORR5bxhSH1xSH5Z5uLPLLII4s8Pl2XBbun8rqGot1TWVpDsZNHll5eDEY9/aynkkcWeWSRRzndFexey+pSS3av5WippU4eWXp9Me715/4h8sgijyzyKKurgt17SV1aye69FC2t1MkjS+8vwksrEfLIIo8s8iivi4I9FtOllNMlHMtYhJZShpZwLPLIMj7RL+XFdwnHIo8s8sgij/nEF+ylnfXd6fW4llLkPtTrcckjy1JeqD7U63HJI4s8sshjXtEFe6nleqe341tqmdvp7fjkkWWpL1Y7vR2fPLLII4s85hdbsJdernd6Oc6ll7mdXo5THlmW/mK108txyiOLPLLIo47Igr2Wcr2TfrxrKXM76ccrjyxrebHaST9eeWSRRxZ51NPFLzkCAEAv4gr22s5e76Qe99rOlu6kHrc8sqztbNBO6nHLI4s8ssijrqiCvdZyvZN2/Gstcztpxy+PtDymGyuVdvzymG6EkMd0I4Q8phsVxRTstZfrnZQ5rL3M7aTMQR7XcvKYbqxcyhzkcU0eWeSRpfYcXIMNAAAFRRRsZ69vaj0PZ0tvaj0PedzUPo/pBlut5yGPm+SRRR5Zas7DGWwAACioecF29vqwVnNxtvSwVnORx2Ht8phucEOrucjjMHlkkUeWWnNpWrCV69vVno8yd7va85HH7ernMd3goNrzkcft5JFFHllqzMclIgAAUJCCDQAABTUr2C4PuZtac3I5wt3UmpM87qZeHtMNblVrTvK4G3lkkUeWuefkDDYAABSkYAMAQEFNCrbLQ44z97xcjnCcueclj+PMn8d0gzuZe17yOI48ssgjy5zzcgYbAAAKUrABAKCg6gXb5SGnmWtuLkc4zVxzk8dp5stjusFR5pqbPE4jjyzyyDLX3JzBBgCAghRsAAAoSMEGAICCFGwAAChIwQYAgIIUbAAAKEjBBgCAghRsAAAoSMEGAICCFGwAAChIwQYAgIIUbAAAKEjBBgCAghRsAAAoSMEGAICCFGwAACioesE+G66mWxxjrrmdncnjFHPNTR6nmS+P6QZHmWtu8jiNPLLII8tcc3MGGwAAClKwAQCgoCYF22Uix5l7Xi5LOM7c85LHcebPY7rBncw9L3kcRx5Z5JFlznk5gw0AAAUp2AAAUFCzgu0ykbupNSeXJdxNrTnJ427q5THd4Fa15iSPu5FHFnlkmXtOzmADAEBBCjYAABTUtGC7TOR2tefjsoTb1Z6PPG5XP4/pBgfVno88biePLPLIUmM+zc9gK9mHtZqLUndYq7nI47B2eUw3uKHVXORxmDyyyCNLrbm4RAQAAAqKKNjOYt/Ueh7Omt7Ueh7yuKl9HtMNtlrPQx43ySOLPLLUnIcz2AAAUFBMwXYW+1rKHJw1vZYyB3lcy8ljurFyKXOQxzV5ZJFHltpziDqDvfaSnXb8ay91accvj7Q8phsrlXb88phuhJDHdCOEPKYbFcVdIrLWkp163GstdanHLY8sa33RSj1ueWSRRxZ51OUabAAAKCiyYK/tLHb68a7trGn68cojy9rOCqUfrzyyyCOLPOqJPYO9lpLdy3GupdT1cpzyyLKWF61ejlMeWeSRRR51RF8isvSS3dvxLb3U9XZ88siy9Bet3o5PHlnkkUUe84u/BnupJbvX41pqqev1uOSRZakvWr0elzyyyCOLPObVxS85jmV0KUV7Cccylp+lFLslHIs8soxP7kt54VrCscgjizyyyGM+XRTsne6L6ULeJOwsoZguiTyyLOGFd0nkkUUeWeRRXlcFe9RrSV1aud7ptRQtrcztyCNLry9aSysPO/LIIo8s8iiru4I9GstqL4W1p5/1VGM56qUg9fSznkoeWcYn/15euHr6WU8ljyzyyCKPcros2DvJ5XUNxfpDyWVpDUXuQ/LIkvxikP5CNQd5ZJFHFnl8uq4L9k5akV1bsf5QWnFaW5H7kDyypL0w9PBCNSd5ZJFHFnmcbhEFe7Q7Y9yq3Lbef5qxRO22FlrvP03rebTef5rxRWK3tdB6/2laz6P1/tO0nkfr/adpPY/W+z/VYgr2vlplt9Z+elerXNXaT+9qzanWfnpX68Wj1n56V2tOtfbTu1pzqrWf3tWaU639zGmRBXtf6RJc+v7WpnTpKn1/a1N6fqXvb21Kv6iUvr+1KT2/0ve3NqXnV/r+1qb0/ErfX2uLL9j79svxqRvl7JexUzfKOTTfYzfK2X+xOXWjnEPzPXajnEPzPXajnEPzPXZbmlUVbAAAmJuCDQAABSnYAABQkIINAAAFKdgAAFCQgg0AAAUp2AAAUJCCDQAABSnYAABQkIINAAAFKdgAAFCQgg0AAAUp2AAAUJCCDQAABSnYAABQkIINAAAFKdgAAFCQgg0AAAUp2AAAUJCCDQAABa2qYF8NZ5+8Uc7V1Wamn7hRzqHH+7Eb5Rx6vB+7Uc6hx/uxG+Ucmu+xG+VcXX36tjSLL9ilF1Pp+1ub0i/+pe9vbUo/nkvf39qUfjyXvr+1Kf14Ln1/a1N6fqXvb21Kl+PS99faIgt2rUVTaz+9q/UiX2s/vav1uK21n97VetzW2k/vaj1ua+2nd7XmVGs/vatVgmvtZ06LKditF0fr/adp/WLeev9pWj8+W+8/TevHZ+v9p2n9+Gy9/zSt59F6/2lal93W+z/VIgp22iJY+6JMe9Fee4mwPrJYH1msjyzyyJJWansq2V0X7PGBn/rgT/7Z5jK+UKe+WCf/bHOxPrJYH1msjyzyyJJ8xjj5Z9vXZcHu6cG+hoXZ04vzGoqE9ZHF+shifWSRR5Zeyuso/WftrmD3+uBe6qLs9cV4qSXC+shifWSxPrLII0svxfpDqT93VwW79wf10hZl7y/CSysR1kcW6yOL9ZFFHll6Ldc7iT9/FwV7fCAv5cG8hGMZX3iX8uK7hGOxPrJYH1msjyzyyDIW097L9U7ascQX7KUsxA/1elxLKQ4f6vW4rI8s1kcW6yOLPLIspVh/KOW4ogv2UhfjTm/Ht9TysNPb8VkfWayPLNZHFnlkWWq53kk4vtiCvfTFuNPLcS69POz0cpzWRxbrI4v1kUUeWZZerndaH2dkwV7LYtxJP961lIed9OO1PrJYH1msjyzyyLKWcr3T8ni7+CVHAADoRVzBXtu73Z3U417b2bmd1OO2PrJYH1msjyzyyLK2s9c7rY47qmCvdTHupB3/WsvDTtrxWx/WRxLrI0vc+pDHdCvDWsv1TovjjynYa1+MOylzWHt52EmZg/VxzfrIYn1kiVkf8tjKeb6abqxc7Tm4BhsAAAqKKNje7d7Ueh7Ozt3Ueh7Wx03WRxbrI0vz9SGPG9o/X0032Ko5D2ewAQCgoOYF27vdw1rNxdm5w1rNxfo4zPrIYn1kabY+5HFQu+er6QY31JpL04JtMd6u9nyUh9vVno/1cTvrI4v1kaX6+pDHreo/X003OKjGfFwiAgAABSnYAABQULOC7eOku6k1Jx9/302tOVkfd2N9ZLE+slRbH/K4k3rPV9MNbjX3nJzBBgCAghRsAAAoqEnB9nHSceael4+/jzP3vKyP41gfWayPLLOvD3kcZf7nq+kGdzLnvJzBBgCAghRsAAAoqHrB9nHSaeaam4+/TzPX3KyP01gfWayPLLOtD3mcZL7nq+kGR5lrbs5gAwBAQQo2AAAUpGADAEBBCjYAABSkYAMAQEEKNgAAFKRgAwBAQQo2AAAUpGADAEBBCjYAABSkYAMAQEEKNgAAFKRgAwBAQQo2AAAUpGADAEBBCjYAABRUvWCfDVfTLY4x19zOzuRxirnmZn2cxvrIYn1kmW19yOMk8z1fTTc4ylxzcwYbAAAKUrABAKCgJgXbx0rHmXtePgY/ztzzsj6OY31ksT6yzL4+5HGU+Z+vphvcyZzzcgYbAAAKUrABAKCgZgXbx0p3U2tOPga/m1pzsj7uxvrIYn1kqbY+5HEn9Z6vphvcau45OYMNAAAFKdgAAFBQ04LtY6Xb1Z6Pj8FvV3s+1sftrI8s1keW6utDHreq/3w13eCgGvNpfgbbojys1VyUiMNazcX6OMz6yGJ9ZGm2PuRxULvnq+kGN9Sai0tEAACgoIiC7V3vTa3n4SzdTa3nYX3cZH1ksT6yNF8f8rih/fPVdIOtmvNwBhsAAAqKKdje9V5LmYOzdNdS5mB9XLM+slgfWWLWhzy2cp6vphsrV3sOUWew174o045/7SUi7fitD+sjifWRJW59yGO6lWHtJbvF8cddIrLWRZl63GstEanHbX1ksT6yWB9Z5JFlrSW71XG7BhsAAAqKLNhre9ebfrxrO0uXfrzWRxbrI4v1kUUeWdZ2Frvl8caewV7LouzlONdSIno5Tusji/WRxfrIIo8saynZrY8z+hKRpS/K3o5v6SWit+OzPrJYH1msjyzyyLL0kp1wfPHXYC91UfZ6XEstEb0el/WRxfrIYn1kkUeWpZbslOPq4pccxwfvUhbmEo5lfLFdSpFYwrFYH1msjyzWRxZ5ZBnL6FKKdtqxdFGwd5bwxLIk3b/wLqQE7VgfWayPLNZHFnlk6b1kJ/78XRXsUa8P6qUtxp1eX4SXVh52rI8s1kcW6yOLPLL0WrJTf+7uCvZofHD38gDv6Wc91fhi3MsLck8/66msjyzWRxbrI4s8soxltZeinf6zdlmwd5If7GtYiB9KfnFeQ3H4kPWRxfrIYn1kkUeW5PKaXqx3ui7YO2kP/LUtxA+lvVCvrTh8yPrIYn1ksT6yyCNLWpHtoVjvLKJgj8ZFsNtaaL3/NOOL9m5rofX+07R+fLbef5rWj8/W+0/T+vHZev9pWs+j9f7T7M4Ytyq3rfd/qsUU7H21Fket/fSu1ot5rf30rtbjttZ+elfrcVtrP72r9bittZ/e1ZpTrf30rlbZrbWfOS2yYO8rvWhK39/alH6RL31/a1P68Vz6/tam9OO59P2tTenHc+n7W5vS8yt9f2tTugSXvr/WFl+w9+0vplM3ytl/8T91o5xDj/djN8o59Hg/dqOcQ4/3YzfKOTTfYzfK2S/Hp25Ls6qCDQAAc1OwAQCgIAUbAAAKUrABAKAgBRsAAApSsAEAoCAFGwAACpqhYI9fZmiz2Ww2m81msy1hO54z2AAAUJCCDQAABSnYAABQ0CcV7Ksrf8sfAID1uEv/Pfvuu++2/9XXX389PHnyRGkGAIAjffvtt8Nnn322ve0SkTu5HF48OBvOzp4Mr6d/Q0WXl8PrF0+GB9sM3m8PHmzyuJz+G6q6fP1hHg+GB09ej1GR4PLF8GDK5YVMqrp88WBvXXxk26wVKrp8Pbx4snmO2s/gwYPhyeYFxPKo4/WTvdnfZVvAGlGw7+DyxS+GZ2+nf6Cuscidnw+Pnr0c3n6Qwdu3L4dH55uirUFUdP1m8/zRh3m8Hd6+fDScnyt07W0y+sWzTSK0cPF7k0+yPRlw/mh49nLzHDX9u63NE9jLR+fD+YMXSjazULB/wHg24ly7bmM8CzcWufH2/cfDq4uL7SVM2+3i1fD8/va/Gt4+Ox+cEKrj9ZPz6c3m/eHxq5t5PN7m8XZ4du6TnpacEGjp9fCbl+P/3h+eX0xr49D25cPtf83MNuV6ezJgvL19DdllcDG8ev8CMpx7AZndwy/3Hv8f2V49nv7jYZPVAtaIgv1Rl5u1qVy3dPnbb6YzDpvF9ubL4eG9e9t/2rr3cHj65uJdyX75a2chZrd5w/PrbXnYJPLqzfDlw5t5fPlmU7K3//By+LXT2G1sMvqF56x2Lv95+N34v/d/Pvx0b3nQwuXwYveEdf/5cLF9Dbn+x80T1vDw6Zvh4t0LyG+cFGht82Zo815o6/GrTVbXN7umYB9w+frF8OTB+Sbs6xeq+/enRUhFl8Nvv5mKwuOffWSx3Rue/mp6y/v2m+G3Ot2s9t/w/OxgIA+Hn+3i+P3F9Q0qen9pyOPH704FUdPF76/XyE9+vHl2oqnXX7z7tO35V08P5nHvpz/f/F9HL4ffaNgNvR6evG/Xw1I+4FGwv+f18MWjZ8N1t77+GPzNr36y/b9Q06Y8v5k+OrpttZ1/Pj1BMrd7T99MH+Ut4+zC0ry7NGR8gfrZ9b+jrst/3p6/Hh4ffgdKRa+vr9W5/dOEe0+HN9PlCa7aaef1k0ebtzijzZuhXy4nCAX7I+5vXqQurj74GJw8uzNGtLd/CYmCUde7S0OWce1ir65/wfHx8Pn597+14vpbj3zMVsflML3X2fTrn/o0Idne68b9518NTxcUloL9PQ+HX15cDW82L1IWZb53ZymGnww/Flgz42VVD86nb664/3xY0EmIDuxdGrKQaxf7tPsFx5fDswPfWnH9rUfnvvWoioth92UuP9m+MFx+/6tFp6/po63XX+y+8ejx8KsltesNBfuA/d+lI9jeO9+PX6fNfK6/sm98sTp/dP0kef/5q+HizeHrHZnHjUtDLIJ2dr/guHV/eDyuhenyg6uLi+HV9dfsbL/1SMme2Y0sxuep8+9/tej0NX1nvqavod2b0o0FvoYr2HTq/Vm78Z2vj8VbGM8S3d/+EvDuOvi3zx4Nv3jiBasal4bk2LtcbfstO0/3PgW9d294+OWbd19D9vbZF761opKxRI9L5Pqyz+kNz/g1fdMbHl/T187li18v8trrHQWbDl2fkdj2ig0fi7fycPjy6s3w5s1m27xoXbx6vi3ab19uXrCcFarg/ZtMayDAwy+n8vbxX5h7+KWvsmzh/vOLDy77vH7D8/5r+n7tD2RVt/dNYQv9WksFm87cLNfjE6cTdxnuPXw6vHl/im74wkmhWbk0pEfnw+e7E6e+yrKO+8+Hrz5ybe+9p7+a3vC8Hb7xPa91Xf52ePdNvL9a5mWFCjYd+X65frOwX4ro3sNfvv/jP75Ydj4uDenUveHHvvW1rlu/k9wbnlZ++O8q9E/BphOvt3/85/1lIcp1JgWihvcvTi+HR7tvRdjfdn+0YfNfPTuf/p3rTFmLez8edk9D9z8/n24d4vmqjf3LQz7fvM1ZJgWbfJebcn32aO+P/4zXOCrXmd5//yzwob3vZ761+PFp7npm2vNVG++/RnHJ31OuYBNuU67P9/7K08X4x3+2/0Blr59MZ0Jv/QXGvSdOBWI27/+q5ke23bXw2zUz/TsLZ1Z3Wh97151efz8z87g3/PTn765Vu+UbWzxfNbH3NYpLXgcKNsHGa65vlmtXhbTz8Gc//AuM+3/y9udL/LVw+Ij36+Ob4fDvy73/1pfxF+/8MaZ53fvpzzfPQqOXw6OPXB71/vlqeX/kJNq7r7S8Pyz5fY2CTax335KwMX6vrOe/xvZ/gfHR9V9Be9cjLjfl4cmDYXfp79L+5C38oHfrY7zu/YO/Ejhe5rb/OyQL/daEKPeeDl+9f8IaHozfz//+CWtTrvefr37pay4runx3Xc6y/wKzgk2o18MXu1ejjZePpo9fb9n8dbS53Ruevnk1XP99huu/gna+m//5pjxcXyTv211Yqc36+Orm+nj3/DRe5rZdHuPvkPhq0VrGS6ne/QXN8fv5d7/we3a+KdfT89XjV56vKrt4f13OYn/BcaRgk+nGn7olx8PhyzcXw8Wrx8P96eTQtfubF6rnw6uLKy9WrNe96/Xx6vnH1sf4OyTWR03bPyhzMb7xuRHIJp/Hw/Px26i822nn1q9Q7N/Zd999dzXe+Prrr4cnT55sfxkGAAC4u2+//Xb47LPPtredwQYAgIIUbAAAKEjBBgCAghRsAAAoSMEGAICCFGwAAChIwQYAgIJuFGzfgQ0AAJ/m7P/9v/939fd///fDf/3Xf03/CgAAONb4h2b+7u/+bjj7h3/4h6u/+Zu/mf41AABwqtevXw8/+vM///Ph1atX27YNAAAc72//9m+Hf/zHfxz+5E/+ZDj73e9+d/Uf//Efw7/+678O//Zv/7b9l3/5l385/NVf/dX0nwMAAB/6p3/6p+Ff/uVfhn//938f/uzP/mz4i7/4i+FP//RPh7Pf//73V//3f/83/M///M/wn//5n8N///d/b2//7//+7/b/scYvPn7qPlJ+OXMJvySacAxLmCNZPKaynJ2dTbdgOY+HJRxHyjF86s9R4zjGfYzbH/7hHw5/9Ed/tL32+o//+I+3t3/0ox8NZ5vmvS3Y4zba3d7/59uUeOFaSqn71PtYyhw+VcLPkMIsrpkD+1JKwBIkzHIpeS5hlmMxXIISWfzQfexmNf7vbhv/f8btD/7gD4b/D4xDfYByVO2TAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "6b3517d9",
   "metadata": {},
   "source": [
    "## 4.1. Moves to Avoid\n",
    "In this example, the computer should avoid a certain move so that the opponent won’t win on the next turn. In the game as shown in the figure below, it’s the red player’s turn. If the red player chooses column 1 as the next move by placing a red disc in column 1, the opponent can win on the following turn by placing a red disc in column 1. Therefore, the red player should\n",
    "avoid this move.\n",
    "\n",
    "![toavoid.png](attachment:toavoid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee57706",
   "metadata": {},
   "source": [
    "We therefore define a function to_avoid() to collect all moves that the AI player should avoid to prevent the opponent from winning in two steps. The function is included in the file ch03util.py, and is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d4dc055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_avoid(env):\n",
    "    toavoid=[]\n",
    "    # look for ones you should avoid\n",
    "    for m in env.validinputs:\n",
    "        if len(env.occupied[m-1])<=4:\n",
    "            env_copy=deepcopy(env)\n",
    "            s,r,done,_=env_copy.step(m) \n",
    "            s,r,done,_=env_copy.step(m)                     \n",
    "            if done and r==-1:\n",
    "                toavoid.append(m) \n",
    "    return toavoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158039d0",
   "metadata": {},
   "source": [
    "Later when we define the AI_think2() function, we'll program in such a way os that the AI player avoids moves generated by the function to_avoid(). "
   ]
  },
  {
   "attachments": {
    "toblock.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5e1f64e7",
   "metadata": {},
   "source": [
    "## 4.2. Moves to Block\n",
    "In the next case, the AI player should block a certain move so the opponent won’t win in two steps. In the game as shown below, it’s the yellow player’s turn. If the yellow player doesn’t choose column 1 in the next move, the opponent can choose column\n",
    "1 and win on the following turn. Therefore, the yellow player should block this move.\n",
    "\n",
    "![toblock.png](attachment:toblock.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b832a20e",
   "metadata": {},
   "source": [
    "Later when we define the AI_think2() function, we iterature through all combinations of move m1 for the AI player and move m2 for the opponent, where m1 is different from m2. If the next two moves m1 and m2 leads to a win for the opponent in two steps, the AI player should block by placing a piece in m2 as the next move.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd5e7d9",
   "metadata": {},
   "source": [
    "## 4.3. A Think-Two-Steps-Ahead AI\n",
    "We define a function AI_think2(). The function first checks if there is a move that wins the game for the AI player right away. If yes, it returns the move. Otherwise, the function checks if there is a move that should be blocked to prevent the opponent from winning two steps ahead. If yes, it blocks the opponents' move. If not, the function checks if there is a move that should be avoided to prevent the opponent from winning two steps ahead. If yes, the AI player randomly picks a valid move that's not one of the moves that should be avoided. \n",
    "\n",
    "The following function AI_think2() is defined in the file in the file ch03util.py in the /utils/ folder. If you have downloaded the file ch03util.py from the book's GitHub repository, the function is already defined in the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0f0dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AI_think2(env):\n",
    "    # See if there is a winning move \n",
    "    winner=AI_think1(env)\n",
    "    # if yes, take it\n",
    "    if winner is not None:\n",
    "        return winner\n",
    "    # look for ones you should block\n",
    "    for m1 in env.validinputs:\n",
    "        for m2 in env.validinputs:\n",
    "            if m1!=m2:\n",
    "                env_copy=deepcopy(env)\n",
    "                s,r,done,_=env_copy.step(m1) \n",
    "                s,r,done,_=env_copy.step(m2)                     \n",
    "                # block your opponent's winning move\n",
    "                if done and r!=0:\n",
    "                    return m2 \n",
    "    # look for ones you should avoid\n",
    "    toavoid=to_avoid()\n",
    "    if len(toavoid)>0:\n",
    "        leftovers=[i for i in env.validinputs if i not in toavoid]\n",
    "        if len(leftovers)>0:\n",
    "            return random.choice(leftovers)\n",
    "    # return None otherwise\n",
    "    return None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a02e01",
   "metadata": {},
   "source": [
    "The function is applies to both players. \n",
    "\n",
    "Next, we'll play against the think-two-steps-ahead AI player and make sure it's working the way we intended it to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6997e023",
   "metadata": {},
   "source": [
    "## 3.2. Play against the Think-Two-Steps-Ahead AI\n",
    "To play against the think-two-steps-ahead AI we just created, we use define the AI_vs_manual() function we have created before to play a game manually. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f085f8",
   "metadata": {},
   "source": [
    "We'll use AI_think2 as the argument in the AI_vs_manual() function. I'll choose to be player O this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f34930dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to be the red or the yellow player?yellow\n",
      "the current state is state=\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "AI has chosen move 3\n",
      "the current state is state=\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]]\n",
      "enter your move:4\n",
      "you have chosen move 4\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  1 -1  0  0  0]]\n",
      "AI has chosen move 2\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  1  1 -1  0  0  0]]\n",
      "enter your move:4\n",
      "you have chosen move 4\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0 -1  0  0  0]\n",
      " [ 0  1  1 -1  0  0  0]]\n",
      "AI has chosen move 4\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0 -1  0  0  0]\n",
      " [ 0  1  1 -1  0  0  0]]\n",
      "enter your move:5\n",
      "you have chosen move 5\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0 -1  0  0  0]\n",
      " [ 0  1  1 -1 -1  0  0]]\n",
      "AI has chosen move 1\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0 -1  0  0  0]\n",
      " [ 1  1  1 -1 -1  0  0]]\n",
      "enter your move:6\n",
      "you have chosen move 6\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0 -1  0  0  0]\n",
      " [ 1  1  1 -1 -1 -1  0]]\n",
      "AI has chosen move 7\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0 -1  0  0  0]\n",
      " [ 1  1  1 -1 -1 -1  1]]\n",
      "enter your move:5\n",
      "you have chosen move 5\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0 -1 -1  0  0]\n",
      " [ 1  1  1 -1 -1 -1  1]]\n",
      "AI has chosen move 3\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  1 -1 -1  0  0]\n",
      " [ 1  1  1 -1 -1 -1  1]]\n",
      "enter your move:6\n",
      "you have chosen move 6\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  1 -1 -1 -1  0]\n",
      " [ 1  1  1 -1 -1 -1  1]]\n",
      "AI has chosen move 7\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  1 -1 -1 -1  1]\n",
      " [ 1  1  1 -1 -1 -1  1]]\n",
      "enter your move:6\n",
      "you have chosen move 6\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0 -1  0]\n",
      " [ 0  0  1 -1 -1 -1  1]\n",
      " [ 1  1  1 -1 -1 -1  1]]\n",
      "AI has chosen move 6\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0]\n",
      " [ 0  0  0  1  0 -1  0]\n",
      " [ 0  0  1 -1 -1 -1  1]\n",
      " [ 1  1  1 -1 -1 -1  1]]\n",
      "enter your move:5\n",
      "you have chosen move 5\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0]\n",
      " [ 0  0  0  1 -1 -1  0]\n",
      " [ 0  0  1 -1 -1 -1  1]\n",
      " [ 1  1  1 -1 -1 -1  1]]\n",
      "AI has chosen move 5\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  1  0]\n",
      " [ 0  0  0  1 -1 -1  0]\n",
      " [ 0  0  1 -1 -1 -1  1]\n",
      " [ 1  1  1 -1 -1 -1  1]]\n",
      "the AI player won\n"
     ]
    }
   ],
   "source": [
    "from utils.ch03util import AI_think2\n",
    "\n",
    "AI_vs_manual(env,AI_think2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e5889e",
   "metadata": {},
   "source": [
    "As you can see above, the AI player has blocked me from winning twice by placing a piece in column 7. Looks like the AI_player2() function can indeed think two steps ahead and block the opponent's winning move.  \n",
    "\n",
    "As an exercise, you can call the AI_vs_manual() and use AI_think2 as its argument and play a game with the AI player. Choose red at the beginning so that the AI player goes second. Create a winning opportunity for yourself and see if the AI blocks your winning move. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9aa1f0",
   "metadata": {},
   "source": [
    "## 4.3. Test the Efficacy of the Think-Two-Steps-Ahead AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2864dd05",
   "metadata": {},
   "source": [
    "We again create an empty list *results* to store game outcomes. We simulate 1000 games. Half the time, the think-one-step-ahead AI player moves first and the other half of the time, the think-two-steps-ahead AI player moves first. This way, one player has a first-mover advantage. second. Whenever the think-two-steps-aheadAI player moves second, we multiple the outcome by -1 so that when a value 1 in the list *results* indicates that the think-two-steps-ahead AI player has won and the think-one-step-ahead AI player has lost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63d36b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for i in range(1000):\n",
    "    # AI moves first if i is an even number\n",
    "    if i%2==0:\n",
    "        result=test_game(AI_think2,AI_think1)\n",
    "        # record game outcome\n",
    "        results.append(result)\n",
    "    # AI moves second if i is an odd number\n",
    "    else:\n",
    "        result=test_game(AI_think1,AI_think2)\n",
    "        # record negative of game outcome\n",
    "        results.append(-result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c3c19",
   "metadata": {},
   "source": [
    "We iterate i from 0 to 999. Whenever i is an even number, we simulate a game and let the think-two-steps-ahead AI player move first. The outcome is added to the list *results*: 1 means the think-two-steps-ahead player wins and -1 means the think-one-step-ahead AI player wins. Whenever i is an odd number, we simulate a game and let the think-one-step-ahead AI player move first. We then multiply the outcome by -1 so that 1 means the think-two-steps-ahead AI player has won. \n",
    "\n",
    "Run the above code cells so that we simulate 1000 games and get the outcome.\n",
    "\n",
    "Next, we count how many times the think-two-steps-ahead AI player has won by counting the number of 1s in the list *results*. Similarly, the number of -1s is the number of times the think-two-steps-ahead AI player has lost. Like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d07476eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the think-two-steps-ahead AI won 859 games\n",
      "the think-two-steps-ahead AI lost 141 games\n",
      "the game has tied 0 games\n"
     ]
    }
   ],
   "source": [
    "# count how many times AI player has won\n",
    "wins=results.count(1)\n",
    "print(f\"the think-two-steps-ahead AI won {wins} games\")\n",
    "# count how many times AI player has lost\n",
    "losses=results.count(-1)\n",
    "print(f\"the think-two-steps-ahead AI lost {losses} games\")\n",
    "# count tie games\n",
    "ties=results.count(0)\n",
    "print(f\"the game has tied {ties} games\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b1c415",
   "metadata": {},
   "source": [
    "Results show that the think-two-steps-ahead AI player has won 859 out of the 1000 games; it has lost to the think-one-step-ahead player 141 times. There is no tie game. This indicates that the think-two-step-ahead AI player is clearly better than the think-one-step-ahead AI player. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21150dcc",
   "metadata": {},
   "source": [
    "# 5. Think Three Steps Ahead\n",
    "This next section will allow the AI player to think up to three steps ahead before taking its turn. If the AI player has no winning move in the next step and the opponent has no winning moves two steps ahead, the AI player will look three steps ahead.\n",
    "It will take the next move that most likely leads to a win in three steps. In particular, if there’s a next move that guarantees the AI player to win in three steps, the AI palyer will select that next move as the best one.\n",
    "Let’s use an example to demonstrate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84715aa",
   "metadata": {},
   "source": [
    "## 5.1. An Example of Winning in Three Steps\n",
    "Consider the example as illustrated in the figure below. The red player is about to move, and if it chooses column 6 as its next move, it can create a double attack and gurantee a win in three steps: the red player can win by placing a piece in column 3 or column 7 in three steps and win the game. The yellow player can either block column 3 or column 7, but not both. "
   ]
  },
  {
   "attachments": {
    "doubleattack.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5873c5f4",
   "metadata": {},
   "source": [
    "![doubleattack.png](attachment:doubleattack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8383c8",
   "metadata": {},
   "source": [
    "## 5.2. Create an AI Player Who Thinks Three Steps Ahead\n",
    "We define a function AI_think3(). The function checks if there is a move that wins the game for the AI player right away or if the opponent has a winning move two steps ahead. If not, the player looks three steps ahead and choose the move that most likely leads to a win.  \n",
    "\n",
    "Run the following code cell to define the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0fc9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AI_think3(env):\n",
    "    # See if there is value from AI_think2() \n",
    "    think2=AI_think2(env)\n",
    "    # if yes, take it\n",
    "    if think2 is not None:\n",
    "        return think2\n",
    "    # look 3 steps ahead\n",
    "    w3=[]\n",
    "    for m1 in env.validinputs:\n",
    "        for m2 in env.validinputs:\n",
    "            for m3 in env.validinputs:\n",
    "                try:\n",
    "                    env_copy=deepcopy(env)\n",
    "                    s,r,done,_=env_copy.step(m1) \n",
    "                    s,r,done,_=env_copy.step(m2)   \n",
    "                    s,r,done,_=env_copy.step(m3)                    \n",
    "                    if done and r!=0:\n",
    "                        w3.append(m1) \n",
    "                except:\n",
    "                    pass\n",
    "    # Choose the most frequent winner\n",
    "    if len(w3)>0:\n",
    "        return max(set(w3),key=w3.count)                \n",
    "    # Take random move otherwise\n",
    "    return random.choice(env.validinputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840da4ef",
   "metadata": {},
   "source": [
    "The function is applies to both player X and player O. \n",
    "\n",
    "Next, we'll play against the think-two-steps-ahead AI player and make sure it's working the way we intended it to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f207d6d",
   "metadata": {},
   "source": [
    "## 5.3. Play against the Think-Three-Steps-Ahead AI\n",
    "To play against the think-three-steps-ahead AI we just created, we use define the AI_vs_manual() function we have created before to play a game manually. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af37ef",
   "metadata": {},
   "source": [
    "We'll use AI_think3 as the argument in the AI_vs_manual() function. I'll choose to be player O and create an opportunity for Player X to have a double attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26a3bd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to be the red or the yellow player?yellow\n",
      "the current state is state=\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "AI has chosen move 3\n",
      "the current state is state=\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]]\n",
      "enter your move:7\n",
      "you have chosen move 7\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 -1]]\n",
      "AI has chosen move 3\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 -1]]\n",
      "enter your move:3\n",
      "you have chosen move 3\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0 -1  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 -1]]\n",
      "AI has chosen move 1\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0 -1  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0]\n",
      " [ 1  0  1  0  0  0 -1]]\n",
      "enter your move:7\n",
      "you have chosen move 7\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0 -1  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 -1]\n",
      " [ 1  0  1  0  0  0 -1]]\n",
      "AI has chosen move 2\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0 -1  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 -1]\n",
      " [ 1  1  1  0  0  0 -1]]\n",
      "enter your move:4\n",
      "you have chosen move 4\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0 -1  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 -1]\n",
      " [ 1  1  1 -1  0  0 -1]]\n",
      "AI has chosen move 2\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0 -1  0  0  0  0]\n",
      " [ 0  1  1  0  0  0 -1]\n",
      " [ 1  1  1 -1  0  0 -1]]\n",
      "enter your move:5\n",
      "you have chosen move 5\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0 -1  0  0  0  0]\n",
      " [ 0  1  1  0  0  0 -1]\n",
      " [ 1  1  1 -1 -1  0 -1]]\n",
      "AI has chosen move 6\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0 -1  0  0  0  0]\n",
      " [ 0  1  1  0  0  0 -1]\n",
      " [ 1  1  1 -1 -1  1 -1]]\n",
      "enter your move:6\n",
      "you have chosen move 6\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0 -1  0  0  0  0]\n",
      " [ 0  1  1  0  0 -1 -1]\n",
      " [ 1  1  1 -1 -1  1 -1]]\n",
      "AI has chosen move 4\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0 -1  0  0  0  0]\n",
      " [ 0  1  1  1  0 -1 -1]\n",
      " [ 1  1  1 -1 -1  1 -1]]\n",
      "enter your move:1\n",
      "you have chosen move 1\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0 -1  0  0  0  0]\n",
      " [-1  1  1  1  0 -1 -1]\n",
      " [ 1  1  1 -1 -1  1 -1]]\n",
      "AI has chosen move 5\n",
      "the current state is state=\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0 -1  0  0  0  0]\n",
      " [-1  1  1  1  1 -1 -1]\n",
      " [ 1  1  1 -1 -1  1 -1]]\n",
      "the AI player won\n"
     ]
    }
   ],
   "source": [
    "from utils.ch03util import AI_think3\n",
    "\n",
    "AI_vs_manual(env,AI_think3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0cf8c1",
   "metadata": {},
   "source": [
    "As you can see above, when the AI player places a piece in column 4, it has created a double attack: it can win by placing a piece in column 1 or column 5. I can only block column 5 or column 1, but not both. So the AI player wins in three steps. \n",
    "\n",
    "As an exercise, you can call the AI_vs_manual() and use AI_think3 as its argument and play a game with the AI player. Choose yellow at the beginning so that the AI player goes first. Create an opportunity for the AI player to have a double attack and see if it indeed places a piece to create a double attack and win in three steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572cd31",
   "metadata": {},
   "source": [
    "## 5.4. The Efficacy of the Think-Three-Steps-Ahead AI\n",
    "Below, we'll the test_game() function to test the efficacy of the think-three-steps-ahead AI against the think-two-steps-ahead AI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5e25a8",
   "metadata": {},
   "source": [
    "We again create an empty list *results* to store game outcomes. We simulate 1000 games. Half the time, the think-three-steps-ahead AI player moves first and the other half of the time, the think-two-steps-ahead AI player moves first. This way, no player has a first-mover advantage. second. Whenever the think-three-steps-ahead AI player moves second, we multiple the outcome by -1 so that a value 1 in the list *results* indicates that the think-three-steps-ahead AI player has won."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdb68745",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for i in range(1000):\n",
    "    # AI moves first if i is an even number\n",
    "    if i%2==0:\n",
    "        result=test_game(env,AI_think3,AI_think2)\n",
    "        # record game outcome\n",
    "        results.append(result)\n",
    "    # AI moves second if i is an odd number\n",
    "    else:\n",
    "        result=test_game(env,AI_think2,AI_think3)\n",
    "        # record negative of game outcome\n",
    "        results.append(-result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f060d",
   "metadata": {},
   "source": [
    "We iterate i from 0 to 999. Whenever i is an even number, we simulate a game and let the think-two-steps-ahead AI player move first. The outcome is added to the list *results*: 1 means the think-two-steps-ahead player wins and -1 means the think-one-step-ahead AI player wins. Whenever i is an odd number, we simulate a game and let the think-one-step-ahead AI player move first. We then multiply the outcome by -1 so that 1 means the think-two-steps-ahead AI player has won. \n",
    "\n",
    "Run the above code cells so that we simulate 1000 games and get the outcome.\n",
    "\n",
    "Next, we count how many times the think-two-steps-ahead AI player has won by counting the number of 1s in the list *results*. Similarly, the number of -1s is the number of times the think-two-steps-ahead AI player has lost. Like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0be4d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the think-three-steps-ahead AI won 566 games\n",
      "the think-three-steps-ahead AI lost 369 games\n",
      "the game has tied 65 times\n"
     ]
    }
   ],
   "source": [
    "# count how many times AI player has won\n",
    "wins=results.count(1)\n",
    "print(f\"the think-three-steps-ahead AI won {wins} games\")\n",
    "# count how many times AI player has lost\n",
    "losses=results.count(-1)\n",
    "print(f\"the think-three-steps-ahead AI lost {losses} games\")\n",
    "# count tie games\n",
    "ties=results.count(0)\n",
    "print(f\"the game has tied {ties} times\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da324945",
   "metadata": {},
   "source": [
    "Results show that the think-two-steps-ahead AI player has won 566 out of the 1000 games; it has lost to the think-one-step-ahead player 369 times. There are a total of 65 tie games. This indicates that the think-three-step-ahead AI player is clearly better than the think-two-steps-ahead AI player. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
