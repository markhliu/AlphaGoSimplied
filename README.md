# AlphaGo Simplified: Ruled-Based AI and Deep Learning in Everyday Games
Implement ideas behind Deep Blue (rule-based AI) and AlphaGo (rule-based AI + Deep Learning) in three simple games: Last Coin Standing, Tic Tac Toe, and Connect Four.


May 11, 1997, was a watershed moment in the history of artificial intelligence (AI). On that day, the IBM supercomputer Chess engine, Deep Blue, beat the world Chess champion, Gary Kasparov. It was the first time a machine has triumphed over humans in a Chess tournament. The news garnered much media attention. However, the algorithm behind Deep Blue, though impressive and powerful, was the traditional rule-based AI, not machine learning (ML) that is ubiquitous in today's high-tech world.

Fast forward 19 years to May 9, 2016, Google DeepMind’s AlphaGo beat the world Go champion Lee Sedol. AI has again stolen the spotlight and generated a media frenzy. This time, a new type of AI algorithm, namely machine learning (more specifically, deep reinforcement learning) was the driving force behind the the game strategies.

You may wonder: What exactly is ML? How is it related to AI? Why is deep learning (DL) so popular these days? In this book, you’ll learn how traditional rule-based AI and Ml work and how you can use them to play everyday games such as the Last Coin stadning, Tic Tac Toe, or Connect Four. Last Coin Standing (the coin game from now onwards) is a game in which two players take turns to remove coins from a pile of 21 coins. A player can remove one or two coins at a time and whoever removes the last coin wins. In Tic Tac Toe, two players take turn to place Xs and Os in a three by three grid; whoever forms three Xs or Os in a row vertically, horizontally, or diagonally wins. In Connect Four, two players take turns dropping discs into one of seven columns. When a disc is dropped into a column, it falls to the lowest available space in the column. The first player who forms a direct line—either horizontally, vertically, or diagonally—with four of their game pieces wins. 

We use the three simple everyday games for a couple of reasons. First, game rules in these games are easy to implement. As a result, readers can focus on learning how to implement rule-based AI, deep reinforcement learning (such as the actor-critic method), and other AI techniques without getting bogged down in complicated game rules. In contrast, Chess and Go require extensive domain knowlege in these areas in roder to design effective game strategies. For example, the position evaluation function used in the Deep Blue algorithm has incorpoated thousands of Chess rules to come up with a good estimate of the value of a board position. To implement a simple Go game, we need to code in rules such as: no self-capturing; komi, compensation for the first-mover's advantage; ko, avoiding creating a previous board position, and so on.

Second, implementing rule-based AI and deep learning in these three simple games is fast and not computationally costly. As you'll see later in the book, we can use a regular computer to train game strategies in a matter of minutes or hours and solve these games (we provide perfect solutions to the first two games in the book; as for Connect Four, there is a known rule-based solution but takes too long to implement; the book doesn't provide a perfect solution for Connect Four, but provide hard-to-beat game strategies). In contrast, training game strategies for Chess and Go is extremely time consuming and requires supercomputing facilities. For example, Deep Blue searched hundreds of millions of board positions each second to find the best next move. AlphaGo used 1920 CPUs and 280 GPUs to train its model. Most readers don't have access to the supercomputing facility needed to train Chess and Go algorithms. Using the three simple games makes learning accessible to anyone with a regular computer. 

By using these three simple games, readers can easily grasp the ideas behind rule-based AI such as the MiniMax algorithm, alpha-beta pruning, and Monte Carlo Tree Search. After that, we'll discuss Machine Learning and in particular deep reinforcement learning that's used in the AlphaGo algorithm. Specifically, the DeepMind team used actor-critic method to create two deep neural networks to train the game strategies. Finally, readers learn to combine deep reinforcemnet learning with rule-based AI, MCTS, to make the game strategies more powerful, as the DeepMind team did in AlphaGo. 

