{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653089c9",
   "metadata": {},
   "source": [
    "# Chapter 4: Minimax Tree Search\n",
    "\n",
    "In this chapter, youâ€™ll learn how minimax algorithms work. You'll use it to play the Last Coin Standing game (a.k.a. the coin game) that we developed in Chapter 1. The algorithm exhausts all possibilities in the coin game. The minimax agent plays perfectly: it always wins when it pays second. \n",
    "\n",
    "The minimax algorithm is a decision rule in artificial intelligence and game theory. The algorithm assumes that each player in the game makes the best possible decisions at each step. Further, each player knows that other players make fully rational decisions as well. In simple games such as the coin game or Tic Tac Toe, the algorithm exhausts all possible game paths and solves the game. This means the minimax algorithm provides the strongest possible for these games and no other algorithms can beat it. \n",
    "\n",
    "In more complicated games such as Connect Four or Chess, the minimax algorithm cannot exhaust all possibilities in a short amount of time. However, modifications on the minimax algorithms such as depth pruning and alpha-beta pruning (which we'll study in the next couple of chapters) make strong game players. In fact, the algorithms used by Deep Blue to beat World Chess Champion Gary Kasparov in 1997 is based on minimax with alpha-beta pruning and powerful position evaluation functions. \n",
    "\n",
    "After this chapter, you'll understand the basic logi behind the minimax algorithm and can design game strategies for any game based on the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b25bf6",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Create a subfolder for files in Chapter 4}}$<br>\n",
    "***\n",
    "We'll put all files in Chapter 4 in a subfolder /files/ch04. Run the code in the cell below to create the subfolder.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117477d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"files/ch04\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ad876",
   "metadata": {},
   "source": [
    "# 1. Introduction to the Minimax Algorithm\n",
    "We'll introduce the minimax algorithm in the section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c437e8",
   "metadata": {},
   "source": [
    "## 1.1. What is the Minimax Algorithm?\n",
    "The minimax algorithm is a decision rule in artificial intelligence and game theory. It's also called the MinMax algorithm. \n",
    "\n",
    "In a nutshell, the algorithm assumes that: \n",
    " \n",
    "*\tEach player in the game makes the best possible decisions at each step;\n",
    "*\tFurther, each player knows that other players make fully rational decisions as well;\n",
    "*\tEach player knows that other players know that he/she makes the best possible decisions;\n",
    "*   and so on...\n",
    "\n",
    "In a two-player game, each player makes decisions to maximize his/her own expected payoff and to minimize the opponent's payoffs. Hence the name minimax. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d7767",
   "metadata": {},
   "source": [
    "## 1.2. The Minimax Algorithm with Backward Induction\n",
    "The solution in a minimax algorithm is achieved through backward induction. It starts with the terminal state of the game. In the coin game, this is when the last coin is taken by a player; in Tic Tac Toe, the terminal state is when the game is tied or when one player has connected three pieces in a row. We find out the payoff to each player in the terminal state. In the second to last stage of the game, the player looks one step ahead and makes the best decision for himself/herself, anticipating that the opponent makes the best decision in the next step, and so on.\n",
    "\n",
    "Let's use the coin game as the example. If both players make the best decisions, the game has seven rounds and 14 steps (in each round, player 1 makes a move and player 2 makes a move). In stage 7, three coins are left in the pile and player 1 has to decide how many coins to take: 1 or 2? At this point, player 1 knows that she will lose for sure: player 2 will take the remaining one or two coins in the pile and win the game. In stage 7, six coins are left in the pile and player 1 has to decide how many coins to take: 1 or 2? Player 1 knows that if she takes 1, player will take 2; if she takes 2, player 2 will take 1. Player 2 will leave three coins in the pile no matter what... In stage 1, 21 coins are in the pile and player 1 has to decide how many coins to take: 1 or 2? Player 1 knows that if she takes 1, player will take 2; if she takes 2, player 2 will take 1. Player 2 will leave 18 coins in the pile no matter what... \n",
    "\n",
    "Since the total number of possible scenarios in a Tic Tac Toe game is small, the minimax algorithm can exhaust all scenarios in a short amount of time and find the best solution for each player in every stage of the game. \n",
    "\n",
    "However, for more complicated games such as Chess and Go, the total number of possible scenarios in a game is astronomical. It's impossible for the minimax algorithm to pick the best move in a reasonable amount of time. We'll discuss how to mitigate this concern in later chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db31da9",
   "metadata": {},
   "source": [
    "# 2. The Minimax Algorithm in the Coin Game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7252a608",
   "metadata": {},
   "source": [
    "We'll use the self-made coin game environment from Chapter 1. Specifically, the module is saved as *coin_env.py* in the folder *utils* in this GitHub repository. Download the file *coin_env.py* and save it in the folder /Desktop/ai/utils/ on your computer.\n",
    "\n",
    "First, let's define a couple of functions that the algorithm will use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ddc025",
   "metadata": {},
   "source": [
    "## 2.1. The minimax() Function\n",
    "We'll define a minimax() function for the player who is about to make a move. The function applies to both player 1 and player 2. The function tells the player what's the best next move, anticipating that the opponent will make the best decision in the next stage as well, and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb8839e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from random import choice\n",
    "\n",
    "def minimax(env):\n",
    "    # create a list to store winning moves\n",
    "    wins=[]\n",
    "    # iterate through all possible next moves\n",
    "    for m in env.validinputs:\n",
    "        # make a hypothetical move and see what happens\n",
    "        env_copy=deepcopy(env)\n",
    "        new_state, reward, done, info = env_copy.step(m) \n",
    "        # If wins right away with move m, take it.\n",
    "        if done and reward==1:\n",
    "            return m \n",
    "        # See what's the best response from the opponent\n",
    "        opponent_payoff=maximized_payoff(env_copy, reward, done)  \n",
    "        # Opponent's payoff is the opposite of your payoff\n",
    "        my_payoff=-opponent_payoff \n",
    "        if my_payoff==1:\n",
    "            wins.append(m)\n",
    "    # pick winning moves if there is any        \n",
    "    if len(wins)>0:\n",
    "        return choice(wins)\n",
    "    # otherwise randomly pick\n",
    "    return choice(env.validinputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05110e83",
   "metadata": {},
   "source": [
    "To search for the best move, the player iterates through all possible next moves. Note that we need to use deepcopy here. In Python, when you make a regular copy of an object, you just create a link to the original object. When you make changes to the copy, the original is changed as well. To avoid this, we need to use deepcopy. Many Python beginners make mistakes on this and couldn't figure out what's wrong with their code.\n",
    "\n",
    "If a player finds a move that allows her to win the game right away, the player stops searching and take the move. Otherwise, the player will see what's the best outcome for the opponent in the next stage, knowing full well that the opponent will make the best decision to maximize the opponent's payoff. Since it's a zero-sum game, the opponent's payoff is the opposite of the current player's payoff. The player will pick winning moves if there is one; otherwise, the player randomly picks a move. \n",
    "\n",
    "Here, we use the *maximized_payoff(env_copy, reward, done)* function to find the best payoff for the opponent in the next stage. Let's define that function next. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099241b6",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Deepcopy in Python}}$<br>\n",
    "***\n",
    "In Python, when you make a regular copy of an object, you just create a link to the original object. When you make changes on the copy, the original is changed as well. To avoid this, we need to use deepcopy when we make hypothetical game moves. Many Python beginners make mistakes on this and couldn't figure out what's wrong with their code.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee28a4e",
   "metadata": {},
   "source": [
    "## 2.2. The *maximized_payoff()* Function \n",
    "Next, we'll define *maximized_payoff(env, reward, done)* function. This function produces the best possible outcome for the next player in the next stage of the game. Note this function applies to any player in any stage of the game so we don't need to define one function for player 1 and another function for player 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a847d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximized_payoff(env, reward, done):\n",
    "    # if the game has ended after the previous player's move\n",
    "    if done:\n",
    "        return -1\n",
    "    # Otherwise, search for action to maximize payoff\n",
    "    best_payoff=-2\n",
    "    # iterate through all possible moves\n",
    "    for m in env.validinputs:\n",
    "        env_copy=deepcopy(env)\n",
    "        new_state,reward,done,info=env_copy.step(m)  \n",
    "        # If I make this move, what's the opponent's response\n",
    "        opponent_payoff=maximized_payoff(env_copy, reward, done)\n",
    "        # Opponent's payoff is the opposite of your payoff\n",
    "        my_payoff=-opponent_payoff \n",
    "        # update your best payoff \n",
    "        if my_payoff>best_payoff:        \n",
    "            best_payoff=my_payoff\n",
    "    return best_payoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6bd0a",
   "metadata": {},
   "source": [
    "If the game has ended after the previous player's move, the function calculates the payoff to the next player based on the game outcome. In this case, it means the previous player has won the game, so the payoff to the current player is -1. If the game has not ended, the player searches for the best action by iterating throug all possible next moves, knowing full well that the opponent will take the best action in the next stage as well.\n",
    "\n",
    "Note here that we have used the *maximized_payoff()* function in the *maximized_payoff()* function itself. This creates an nested loop. The function keeps on searching to the next level until the game ends. The process exhausts all game scenarios in the coin game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977029b",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Use A Function in the Function Itself}}$<br>\n",
    "***\n",
    "In Python, you can put a function in the function itself. This creates an infinite loop. The function keeps on going to the next stage until a certain condition is met. In the case of the maximized_payoff() function above. The infinite loop stops until the coin game is finished (that is, there is no coin left in the pile and a player has won). The process exhausts all game scenarios. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d963a4e3",
   "metadata": {},
   "source": [
    "## 2.3. Play Against the Minimax Algorithm \n",
    "Next, you'll play a game against the minimax algorithm. We'll let the minimax algorithm move second and see if it wins the game 100% of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b9c0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter a move in the form of 1 or 2\n",
      "there are 21 coins in the pile\n",
      "Player 1, what's your choice: 1 or 2?2\n",
      "Player 1 has chosen action=2\n",
      "there are 19 coins in the pile\n",
      "Player 2 has chosen action=1\n",
      "there are 18 coins in the pile\n",
      "Player 1, what's your choice: 1 or 2?1\n",
      "Player 1 has chosen action=1\n",
      "there are 17 coins in the pile\n",
      "Player 2 has chosen action=2\n",
      "there are 15 coins in the pile\n",
      "Player 1, what's your choice: 1 or 2?1\n",
      "Player 1 has chosen action=1\n",
      "there are 14 coins in the pile\n",
      "Player 2 has chosen action=2\n",
      "there are 12 coins in the pile\n",
      "Player 1, what's your choice: 1 or 2?2\n",
      "Player 1 has chosen action=2\n",
      "there are 10 coins in the pile\n",
      "Player 2 has chosen action=1\n",
      "there are 9 coins in the pile\n",
      "Player 1, what's your choice: 1 or 2?2\n",
      "Player 1 has chosen action=2\n",
      "there are 7 coins in the pile\n",
      "Player 2 has chosen action=1\n",
      "there are 6 coins in the pile\n",
      "Player 1, what's your choice: 1 or 2?1\n",
      "Player 1 has chosen action=1\n",
      "there are 5 coins in the pile\n",
      "Player 2 has chosen action=2\n",
      "there are 3 coins in the pile\n",
      "Player 1, what's your choice: 1 or 2?1\n",
      "Player 1 has chosen action=1\n",
      "there are 2 coins in the pile\n",
      "Player 2 has chosen action=2\n",
      "there are 0 coins in the pile\n",
      "Player 2 has won!\n"
     ]
    }
   ],
   "source": [
    "from utils.coin_env import coin_game\n",
    "\n",
    "# Initiate the game environment\n",
    "env=coin_game()\n",
    "state=env.reset()   \n",
    "print(\"enter a move in the form of 1 or 2\")\n",
    "# Play a full game\n",
    "while True:\n",
    "    print(f\"there are {state} coins in the pile\")   \n",
    "    action = input(\"Player 1, what's your choice: 1 or 2?\")\n",
    "    print(f\"Player 1 has chosen action={action}\")    \n",
    "    state, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        print(f\"there are {state} coins in the pile\")\n",
    "        print(f\"Player 1 has won!\") \n",
    "        break\n",
    "    print(f\"there are {state} coins in the pile\") \n",
    "    action = minimax(env)\n",
    "    print(f\"Player 2 has chosen action={action}\")  \n",
    "    state, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        print(f\"there are {state} coins in the pile\")\n",
    "        print(f\"Player 2 has won!\") \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2033eed1",
   "metadata": {},
   "source": [
    "The minimax algorithm wins the game. It makes sure the number of coins in the pile is a multiple of 3: 18, 15, 12, 9, 6, and then 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ece520",
   "metadata": {},
   "source": [
    "# 3. Test the Efficacy of the Minimax Algorithm\n",
    "Next, weâ€™ll test how often the Minimax Algorithm wins against the rule-based AI game strategy that we developed in Chapter 1. We'll first define a few functions in the ch04util module. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879bcb2c",
   "metadata": {},
   "source": [
    "## 3.1. The test_coin_game() Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d3821",
   "metadata": {},
   "source": [
    "Download the file ch04util.py from the book's GitHub repository and save it in /Desktop/ai/utils/ on your computer. The file acts as a local module with a few functions in it.\n",
    "\n",
    "The first two functions are maximized_payoff() and minimax() and they are exactly the same as we have defined in the last section. The third function is rule_based_AI() function, which is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a19f5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_AI(env):\n",
    "    state=int(env.state)\n",
    "    if state%3 != 0:\n",
    "        move = state%3\n",
    "    else:\n",
    "        move = choice([1,2])\n",
    "    return move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c438ab6",
   "metadata": {},
   "source": [
    "The function is similar to the one we have defined in Chapter 1, except that it doesn't take any arguments. It generates the variable *state* based on the current game state in the coin game environment. \n",
    "\n",
    "The fourth function is the random_player() function. The function randomly picks a legal move, and is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6573f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_player(env):\n",
    "    return choice(env.validinputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a05d81",
   "metadata": {},
   "source": [
    "The last function is the test_coin_game() function. It test a coin game between two game strategies. The function takes two arguments: player1 and player2, both are function names. For example, if we put minimax and random_player as the two arguments and in that order, the test_coin_game() function simulates a game between the minimax strategy and a random-move strategy, where the minimax strategy moves first. The test_coin_game() function returns the game outcome: 1 if player 1 wins and -1 if player 2 wins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9c5e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_coin_game(env,player1,player2):\n",
    "    state=env.reset()   \n",
    "    while True:\n",
    "        action=player1(env)   \n",
    "        nstate,reward,done,info=env.step(action)\n",
    "        if done:\n",
    "            return 1 \n",
    "        action=player2(env)   \n",
    "        nstate,reward,done,info=env.step(action)\n",
    "        if done:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbe6000",
   "metadata": {},
   "source": [
    "## 3.2. The Minimax Agent versus Random Moves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1417875",
   "metadata": {},
   "source": [
    "Next, we'll see how good the minimax algorithm is when it plays against random moves. To speed up testing, we created a new game environment for the coin game, which is in the file coin_simple_env.py in the folder /utils/. It's the same as coin_env.py except that we omit the graphical game window functionality. As a result, you cannot use the render() method in the simplified game environment. \n",
    "\n",
    "We simulate 100 games and let the minimax agent move first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b94f675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the minimax algorithm won 99 games\n",
      "the minimax algorithm lost 1 games\n",
      "the game has tied 0 games\n"
     ]
    }
   ],
   "source": [
    "from utils.ch04util import minimax, random_player, test_coin_game\n",
    "from utils.coin_env import coin_game\n",
    "\n",
    "env=coin_game()\n",
    "results=[]\n",
    "for i in range(100):\n",
    "    # minimax moves second \n",
    "    result=test_coin_game(env,minimax,random_player)\n",
    "    # record game outcome\n",
    "    results.append(result)\n",
    "\n",
    "# count how many times minimax has won\n",
    "wins=results.count(1)\n",
    "print(f\"the minimax algorithm won {wins} games\")\n",
    "# count how many times AI player has lost\n",
    "losses=results.count(-1)\n",
    "print(f\"the minimax algorithm lost {losses} games\")\n",
    "# count tie games\n",
    "ties=results.count(0)\n",
    "print(f\"the game has tied {ties} games\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b208ef",
   "metadata": {},
   "source": [
    "Results above show that the minimax agent has won 99 games out of 100. \n",
    "\n",
    "Since we know that if both players use perfect strategies, the second player always wins, we'll see what happens if the minimax agent moves second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9da020e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the minimax algorithm won 100 games\n",
      "the minimax algorithm lost 0 games\n",
      "the game has tied 0 games\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for i in range(100):\n",
    "    # minimax moves second \n",
    "    result=test_coin_game(random_player,minimax)\n",
    "    # record negative game outcome\n",
    "    results.append(-result)\n",
    "\n",
    "# count how many times minimax has won\n",
    "wins=results.count(1)\n",
    "print(f\"the minimax algorithm won {wins} games\")\n",
    "# count how many times AI player has lost\n",
    "losses=results.count(-1)\n",
    "print(f\"the minimax algorithm lost {losses} games\")\n",
    "# count tie games\n",
    "ties=results.count(0)\n",
    "print(f\"the game has tied {ties} games\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10129834",
   "metadata": {},
   "source": [
    "We record the negative of the game outcome so that a value of 1 in the list *results* indicates that the minimax agent has won. The output from the above cell shows that the minimax agent has won all 100 games. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61143017",
   "metadata": {},
   "source": [
    "## 3.3. The Minimax Agent versus Rule-Based AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e136b",
   "metadata": {},
   "source": [
    "Next, we'll see how good the minimax algorithm is when it plays against the rule-based AI agent that we developed in Chapter 1. Below, we simulate 100 games and let the minimax agent move first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2328736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the minimax algorithm won 0 games\n",
      "the minimax algorithm lost 100 games\n",
      "the game has tied 0 games\n"
     ]
    }
   ],
   "source": [
    "from utils.ch04util import rule_based_AI\n",
    "\n",
    "results=[]\n",
    "for i in range(100):\n",
    "    # minimax moves second \n",
    "    result=test_coin_game(env,minimax,rule_based_AI)\n",
    "    # record game outcome\n",
    "    results.append(result)\n",
    "\n",
    "# count how many times minimax has won\n",
    "wins=results.count(1)\n",
    "print(f\"the minimax algorithm won {wins} games\")\n",
    "# count how many times AI player has lost\n",
    "losses=results.count(-1)\n",
    "print(f\"the minimax algorithm lost {losses} games\")\n",
    "# count tie games\n",
    "ties=results.count(0)\n",
    "print(f\"the game has tied {ties} games\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42ef9d",
   "metadata": {},
   "source": [
    "Results above show that the minimax agent has lost all 100 games. Since we know that if both players use perfect strategies, the second player always wins, we'll see what happens if the minimax agent moves second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "811ad71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the minimax algorithm won 100 games\n",
      "the minimax algorithm lost 0 games\n",
      "the game has tied 0 games\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for i in range(100):\n",
    "    # minimax moves second \n",
    "    result=test_coin_game(env,rule_based_AI,minimax)\n",
    "    # record negative game outcome\n",
    "    results.append(-result)\n",
    "\n",
    "# count how many times minimax has won\n",
    "wins=results.count(1)\n",
    "print(f\"the minimax algorithm won {wins} games\")\n",
    "# count how many times AI player has lost\n",
    "losses=results.count(-1)\n",
    "print(f\"the minimax algorithm lost {losses} games\")\n",
    "# count tie games\n",
    "ties=results.count(0)\n",
    "print(f\"the game has tied {ties} games\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28496a3e",
   "metadata": {},
   "source": [
    "The output from the above cell shows that the minimax agent has won all 100 games. \n",
    "\n",
    "Taken together, our results show that the minimax agent plays the game perfectly in the sense that whenever it plays second, it wins 100% of the time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
