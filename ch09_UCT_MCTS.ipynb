{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653089c9",
   "metadata": {},
   "source": [
    "# Chapter 9: Upper Confidence Bounds in MCTS\n",
    "\n",
    "Your learned the basic idea behind Monte Carlo Tree Search (MCTS) in the last chapter. Instead of using a breadth-first approach such as depth pruning or alpha-beta pruning in minimax, MCTS uses a depth-first approach. An MCTS agent simulates a certain number of games all the way to the terminal state to see the game outcome. It then selects the best next move based on the simulation outcomes. \n",
    "\n",
    "In the last chapter, we used a naive move-selection approach. That is, when simulating games, the MCTS agent randomly selects the next move. This leads to some inefficiecies. For example, the same path may be explored multiple times while other paths may never be visited. In this chapter, you'll use the Upper Confidence Bounds for Trees (UCT) method to correct these inefficiencies and make the MCTS algorithm more powerful. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b25bf6",
   "metadata": {},
   "source": [
    "***\n",
    "$\\mathbf{\\text{Create a subfolder for files in Chapter 9}}$<br>\n",
    "***\n",
    "We'll put all files in Chapter 9 in a subfolder /files/ch09. Run the code in the cell below to create the subfolder.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117477d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"files/ch09\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ad876",
   "metadata": {},
   "source": [
    "# 1. Upper Confidence Bounds for Trees (UCT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d7767",
   "metadata": {},
   "source": [
    "This section introduces the concept of Upper Confidence Bounds for Trees (UCT) method. We'll discuss the intuition behand it and the formula we use for move selection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db31da9",
   "metadata": {},
   "source": [
    "## 1.1. The UCT Formala"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7252a608",
   "metadata": {},
   "source": [
    "The idea behind UCT MCTS is to select the next move based on a formula instead of randomly selecting a move. The Upper Confidence Bounds (UCB) formula is as follows:\n",
    "$$UCB=v_i+C\\times \\sqrt{\\frac {logN}{n_i}}$$\n",
    "\n",
    "In the above formula, the value $v_i$ is the estimated value of choosing the next move i. C is a constant that adjusts how much exploration one wants in move selection. N is the total number of times the parent node has been visited, whereas $n_i$ is the number of times that move i has been selected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28f0581",
   "metadata": {},
   "source": [
    "## 1.2. Exploitation versus Exploration\n",
    "The temperature constant, C, controls the balance between exploitation and exploration. When the value of C is large, the formula favors unexplored nodes so that the MCTS agent can examine all nodes and consider all possibilities. When C is small, the agent focuses on the most promising node so far. The theoretical value of C is $\\sqrt{2}$, so you can set the value of C at 1.4 as a starter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee28a4e",
   "metadata": {},
   "source": [
    "# 2. Implement UCT MCTS in Tic Tac Toe\n",
    "We'll implement the UCT MCTS agent in Tic Tac Toe in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfdfde6",
   "metadata": {},
   "source": [
    "## 2.1. The uct_simulate_ttt() Function\n",
    "We first define a uct_select() function to implement the UCB formula so that a move is selected when simulating a game. Download the file ch09util.py from the book's GitHub repository and place it in the folder /Desktop/ai/utils/ on your computer. The function is defined in the file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9873fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uct_select(env_copy,path,paths,temperature):\n",
    "    # use uct to select move\n",
    "    parent=[]\n",
    "    pathvs=[]\n",
    "    for v in env_copy.validinputs:\n",
    "        pathv=path+str(v)\n",
    "        pathvs.append(pathv)\n",
    "        for p in paths:\n",
    "            if p[0]==pathv:\n",
    "                parent.append(p)\n",
    "    # calculate uct score for each action\n",
    "    uct={}\n",
    "    for pathv in pathvs:\n",
    "        history=[p for p in parent if p[0]==pathv]\n",
    "        if len(history)==0:\n",
    "            uct[pathv]=float(\"inf\")\n",
    "        else:\n",
    "            uct[pathv]=sum([p[1] for p in history])/len(history)+\\\n",
    "                temperature*sqrt(log(len(parent))/len(history))    \n",
    "    move=max(uct,key=uct.get)\n",
    "    move=int(move[-1])\n",
    "    return move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7961b4",
   "metadata": {},
   "source": [
    "We use a string variable *path* to denote the game history. For example \"54\" means the current player occupied cell 5; after that, the opponent placed a game piece in cell 4. \n",
    "\n",
    "Once we know how to select moves, we can simulate a full Tic Tac Toe game using the UCT formula. The uct_simulate_ttt() function is defined in the file ch09util.py that you just downloaded. The function is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b589d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uct_simulate_ttt(env,paths,counts,wins,losses,temperature):\n",
    "    env_copy=deepcopy(env)\n",
    "    actions=[]\n",
    "    path=\"\"\n",
    "    # play a full game\n",
    "    while True:\n",
    "        utc_move=uct_select(env_copy,path,paths,temperature)\n",
    "        #move=random.choice(env_copy.validinputs)\n",
    "        move=deepcopy(utc_move)\n",
    "        actions.append(move)\n",
    "        state,reward,done,info=env_copy.step(move)\n",
    "        path += str(move)\n",
    "        if done:\n",
    "            result=0\n",
    "            counts[actions[0]] += 1\n",
    "            if (reward==1 and env.turn==\"X\") or \\\n",
    "                (reward==-1 and env.turn==\"O\"):\n",
    "                result=1\n",
    "                wins[actions[0]] += 1\n",
    "            if (reward==-1 and env.turn==\"X\") or \\\n",
    "                (reward==1 and env.turn==\"O\"):\n",
    "                result=-1\n",
    "                losses[actions[0]] += 1                \n",
    "            break\n",
    "    return result,path,counts,wins,losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0512065",
   "metadata": {},
   "source": [
    "The function rolls out a game till the terminal game state is reached. Each move is selected using the uct_select() function we just defined. Depending on the game outcome, it updates the dictionaries *counts*, *wins*, and *losses*. The function also returns the game outcome and the game path (that is, moves made by the two players). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da24fc",
   "metadata": {},
   "source": [
    "## 2.2. An UCT MCTS Agent for Tic Tac Toe\n",
    "Next, the agent can roll out many games and select the best next move based on the game outcome. To do that, the UCT MCTS agent needs to backpropagate game outcome after each complete game. The backpropagate() function below accomplishes that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3051794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backpropagate\n",
    "def backpropagate(path,result,paths):\n",
    "    while path != \"\":\n",
    "        paths.append((path,result))\n",
    "        path=path[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ceeb35",
   "metadata": {},
   "source": [
    "The backpropagate() function takes three arguments. The first arguemnt *path* is a string variable with the moves made by the two players. The second argument *result* indicates the game outcome (1 means the current player wins, -1 means the current player loses, and 0 means a tie game). The third argument *paths* is a list of path-result pairs. After each rollout, the backpropagate() function retroactively add path-result pairs to the list *paths*. \n",
    "\n",
    "After the agent finishes the fixed number of rollouts, it selects the best next move based on the numbers recorded in the three dictionaries *counts*, *wins*, and *losses*, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52448c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_move(counts,wins,losses):\n",
    "    # See which action is most promising\n",
    "    scores={}\n",
    "    for k,v in counts.items():\n",
    "        if v==0:\n",
    "            scores[k]=0\n",
    "        else:\n",
    "            scores[k]=(wins.get(k,0)-losses.get(k,0))/v\n",
    "    best_move=max(scores,key=scores.get)  \n",
    "    return best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75e747d",
   "metadata": {},
   "source": [
    "This function selects the best move based on the numbers in the three dictionaries. It calculates a score for each potential next move: the score is the difference between the number of wins and losses scaled by the total number of moves. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e851bb",
   "metadata": {},
   "source": [
    "Finally, we define the uct_mcts_ttt() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a9a82b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uct_mcts_ttt(env,num_rollouts=100,temperature=1.4):\n",
    "    if len(env.validinputs)==1:\n",
    "        return env.validinputs[0]\n",
    "    counts={}\n",
    "    wins={}\n",
    "    losses={}\n",
    "    for move in env.validinputs:\n",
    "        counts[move]=0\n",
    "        wins[move]=0\n",
    "        losses[move]=0\n",
    "    paths=[]    \n",
    "    # roll out games\n",
    "    for _ in range(num_rollouts):\n",
    "        result,path,counts,wins,losses=uct_simulate_ttt(\\\n",
    "         env,paths,counts,wins,losses,temperature)      \n",
    "        # backpropagate\n",
    "        backpropagate(path,result,paths)\n",
    "    # See which action is most promising\n",
    "    best_next_move=best_move(counts,wins,losses) \n",
    "    return best_next_move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91376624",
   "metadata": {},
   "source": [
    "We set the default number of roll outs to 100. If there is only one legal move left, we skip searching and select the only move available. Otherwise, we create three dicitonaries counts, wins, and losses to record the outcomes from simulated games. Once the rollouts are complete, the agent selects the best next move based on the simulation results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b208ef",
   "metadata": {},
   "source": [
    "With 100 simulations each step, the MCTS agent is not very strong. But let's see whehter it's better than a rnanom player"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9084e2e",
   "metadata": {},
   "source": [
    "# 3. Test the UCT MCTS Agent in Tic Tac Toe\n",
    "In this section, we'll first play a game manually against the UCT MCTS agent in Tic Tac Toe. We then test 100 games and see how effective it is. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f8f81",
   "metadata": {},
   "source": [
    "## 3.1. Manually Play against the UCT MCTS Agent\n",
    "We let the UCT MCTS agent move first in Tic Tac Toe. We use the input() function to key in the moves for Player O. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77c6b520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player X has chosen 5\n",
      "the current state is \n",
      "[[0 0 0]\n",
      " [0 1 0]\n",
      " [0 0 0]]\n",
      "What's your move, player 1?4\n",
      "Player O has chosen 4\n",
      "the current state is \n",
      "[[ 0  0  0]\n",
      " [-1  1  0]\n",
      " [ 0  0  0]]\n",
      "Player X has chosen 1\n",
      "the current state is \n",
      "[[ 1  0  0]\n",
      " [-1  1  0]\n",
      " [ 0  0  0]]\n",
      "What's your move, player 1?9\n",
      "Player O has chosen 9\n",
      "the current state is \n",
      "[[ 1  0  0]\n",
      " [-1  1  0]\n",
      " [ 0  0 -1]]\n",
      "Player X has chosen 3\n",
      "the current state is \n",
      "[[ 1  0  1]\n",
      " [-1  1  0]\n",
      " [ 0  0 -1]]\n",
      "What's your move, player 1?2\n",
      "Player O has chosen 2\n",
      "the current state is \n",
      "[[ 1 -1  1]\n",
      " [-1  1  0]\n",
      " [ 0  0 -1]]\n",
      "Player X has chosen 7\n",
      "the current state is \n",
      "[[ 1 -1  1]\n",
      " [-1  1  0]\n",
      " [ 1  0 -1]]\n",
      "Player 1 has won!\n"
     ]
    }
   ],
   "source": [
    "from utils.ttt_simple_env import ttt\n",
    "from utils.ch09util import uct_mcts_ttt\n",
    "\n",
    "env=ttt()\n",
    "state=env.reset() \n",
    "while True:\n",
    "    action=uct_mcts_ttt(env,num_rollouts=1000)\n",
    "    print(f\"Player {env.turn} has chosen {action}\")    \n",
    "    state, reward, done, info = env.step(action)\n",
    "    print(f\"the current state is \\n{env.state.reshape(3,3)}\")\n",
    "    if done:\n",
    "        if reward==1:\n",
    "            print(\"Player 1 has won!\") \n",
    "        else:\n",
    "            print(\"Game over, it's a tie!\")    \n",
    "        break  \n",
    "    action=int(input(\"What's your move, player 1?\"))\n",
    "    print(f\"Player {env.turn} has chosen {action}\")    \n",
    "    state, reward, done, info = env.step(action)\n",
    "    print(f\"the current state is \\n{env.state.reshape(3,3)}\")\n",
    "    if done:\n",
    "        print(\"Player 2 has won!\") \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f64e6ef",
   "metadata": {},
   "source": [
    "We set the number of rollouts to 1000. It takes a few seconds for the UCT MCTS agent to make a move. The MCTS agent is able to create a double attack and win the game. This shows that the UCT MCTS agent is very strong. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0e0986",
   "metadata": {},
   "source": [
    "## 3.2. Effectiveness of the Tic Tac Toe MCTS Agent\n",
    "We will let the naive MCTS agent play against a random player 100 games and see how many times it wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c8e35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "results=[]\n",
    "for i in range(100):\n",
    "    state=env.reset() \n",
    "    if i%2==0:\n",
    "        action=random.choice(env.validinputs)\n",
    "        state, reward, done, info=env.step(action)\n",
    "    while True:\n",
    "        action=uct_mcts_ttt(env,num_rollouts=1000)  \n",
    "        state, reward, done, info=env.step(action)\n",
    "        if done:\n",
    "            # result is 1 if the MCTS agent wins\n",
    "            if reward!=0:\n",
    "                results.append(1) \n",
    "            else:\n",
    "                results.append(0)    \n",
    "            break  \n",
    "        action=random.choice(env.validinputs)   \n",
    "        state, reward, done, info=env.step(action)\n",
    "        if done:\n",
    "            # result is -1 if the random-move agent wins\n",
    "            if reward!=0:\n",
    "                results.append(-1) \n",
    "            else:\n",
    "                results.append(0)    \n",
    "            break  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f47310c",
   "metadata": {},
   "source": [
    "Half the time, the MCTS agent moves first so that no player has an advantage. We record a result of 1 if the UCT MCTS agent wins and a result of -1 if the UCT MCTS agent loses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab103f9",
   "metadata": {},
   "source": [
    "We now count how many times the MCTS agent with pruning has won and lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ee606e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the MCTS agent has won 99 games\n",
      "the MCTS agent has lost 0 games\n",
      "the game has tied 1 times\n"
     ]
    }
   ],
   "source": [
    "# count how many times the MCTS agent won\n",
    "wins=results.count(1)\n",
    "print(f\"the MCTS agent has won {wins} games\")\n",
    "# count how many times the MCTS agent lost\n",
    "losses=results.count(-1)\n",
    "print(f\"the MCTS agent has lost {losses} games\")  \n",
    "# count how many tie games\n",
    "losses=results.count(0)\n",
    "print(f\"the game has tied {losses} times\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743f454f",
   "metadata": {},
   "source": [
    "The above results show that the MCTS agent is much better than the random agent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c826b4",
   "metadata": {},
   "source": [
    "# 4. A UCT MCTS Agent in Connect Four\n",
    "Next, we create a UCT MCTS agent in Connect Four and see how effective it is. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be468a",
   "metadata": {},
   "source": [
    "## 4.1. Create A Connect Four UCT MCTS Agent\n",
    "Similar to the UCT MCTS agent for Tic Tac Toe, we create a UCT MCTS agent for Connect Four. In the local module ch09util.py, we define a couple of functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "286f210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uct_simulate_conn(env,paths,counts,wins,losses,temperature):\n",
    "    env_copy=deepcopy(env)\n",
    "    actions=[]\n",
    "    path=\"\"\n",
    "    while True:\n",
    "        utc_move=uct_select(env_copy,path,paths,temperature)\n",
    "        move=deepcopy(utc_move)\n",
    "        actions.append(move)\n",
    "        state,reward,done,info=env_copy.step(move)\n",
    "        path += str(move)\n",
    "        if done:\n",
    "            result=0\n",
    "            counts[actions[0]] += 1\n",
    "            if (reward==1 and env.turn==\"red\") or \\\n",
    "                (reward==-1 and env.turn==\"yellow\"):\n",
    "                result=1\n",
    "                wins[actions[0]] += 1\n",
    "            if (reward==-1 and env.turn==\"red\") or \\\n",
    "                (reward==1 and env.turn==\"yellow\"):\n",
    "                result=-1\n",
    "                losses[actions[0]] += 1                \n",
    "            break\n",
    "    return result,path,counts,wins,losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa1132",
   "metadata": {},
   "source": [
    "The uct_simulate_conn() function above simulate a Connect Four game till the terminal state. Note that it uses the same uct_select() function that we used for Tic Tic Toe to select the next move when deciding which child node to select. It uses the same UCT formula when doing so. \n",
    "\n",
    "The uct_simulate_conn() then updates the number of games simulated, as well as the number of wins and losses for the current player. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd1ef3",
   "metadata": {},
   "source": [
    "Furhter, we define a uct_mcts_conn() function in the local module as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85f4548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uct_mcts_conn(env,num_rollouts=100,temperature=1.4):\n",
    "    if len(env.validinputs)==1:\n",
    "        return env.validinputs[0]\n",
    "    counts={}\n",
    "    wins={}\n",
    "    losses={}\n",
    "    for move in env.validinputs:\n",
    "        counts[move]=0\n",
    "        wins[move]=0\n",
    "        losses[move]=0\n",
    "    paths=[]    \n",
    "    # roll out games\n",
    "    for _ in range(num_rollouts):\n",
    "        result,path,counts,wins,losses=uct_simulate_conn(\\\n",
    "         env,paths,counts,wins,losses,temperature)      \n",
    "        # backpropagate\n",
    "        backpropagate(path,result,paths)\n",
    "    # See which action is most promising\n",
    "    best_next_move=best_move(counts,wins,losses) \n",
    "    return best_next_move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5cfdd3",
   "metadata": {},
   "source": [
    "The default number of rollouts is 100. After each rollout, the function backpropagates to update winning and losing statistics. Finally, it uses the best_move() function to select the best next move based on the difference in the winning and losing proabilities for each next move.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c69390c",
   "metadata": {},
   "source": [
    "## 4.2. Play against the Connect Four MCTS Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a93930e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's your move, player red?4\n",
      "Player red has chosen 4\n",
      "the current state is \n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]]\n",
      "Player yellow has chosen 1\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [-1  0  0  1  0  0  0]]\n",
      "What's your move, player red?3\n",
      "Player red has chosen 3\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [-1  0  1  1  0  0  0]]\n",
      "Player yellow has chosen 1\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0  0]\n",
      " [-1  0  1  1  0  0  0]]\n",
      "What's your move, player red?5\n",
      "Player red has chosen 5\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0  0]\n",
      " [-1  0  1  1  1  0  0]]\n",
      "Player yellow has chosen 1\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0  0]\n",
      " [-1  0  1  1  1  0  0]]\n",
      "What's your move, player red?5\n",
      "Player red has chosen 5\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0  0]\n",
      " [-1  0  0  0  1  0  0]\n",
      " [-1  0  1  1  1  0  0]]\n",
      "Player yellow has chosen 1\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0  0]\n",
      " [-1  0  0  0  1  0  0]\n",
      " [-1  0  1  1  1  0  0]]\n",
      "Player yellow has won!\n"
     ]
    }
   ],
   "source": [
    "from utils.conn_simple_env import conn\n",
    "from utils.ch09util import uct_mcts_conn\n",
    "\n",
    "# Initiate the game environment\n",
    "env=conn()\n",
    "state=env.reset() \n",
    "while True:\n",
    "    action=int(input(\"What's your move, player red?\"))\n",
    "    print(f\"Player {env.turn} has chosen {action}\")    \n",
    "    state, reward, done, info = env.step(action)\n",
    "    print(f\"the current state is \\n{env.state.T[::-1]}\")\n",
    "    if done:\n",
    "        print(\"Player red has won!\") \n",
    "    action=uct_mcts_conn(env,num_rollouts=500)\n",
    "    print(f\"Player {env.turn} has chosen {action}\")    \n",
    "    state, reward, done, info = env.step(action)\n",
    "    print(f\"the current state is \\n{env.state.T[::-1]}\")\n",
    "    if done:\n",
    "        if reward!=0:\n",
    "            print(\"Player yellow has won!\") \n",
    "        else:\n",
    "            print(\"Game over, it's a tie!\")    \n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785e7c31",
   "metadata": {},
   "source": [
    "The MCTS agent is not very strong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c97da9",
   "metadata": {},
   "source": [
    "## 4.3. Effectiveness of the Connect Four MCTS Agent\n",
    "We will let the naive MCTS agent play against a random player 100 games and see how many times it wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c70da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for i in range(100):\n",
    "    state=env.reset() \n",
    "    if i%2==0:\n",
    "        action=random.choice(env.validinputs)\n",
    "        state, reward, done, info = env.step(action)\n",
    "    while True:\n",
    "        action=uct_mcts_conn(env,num_rollouts=100)  \n",
    "        state, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            # result is 1 if the MCTS agent wins\n",
    "            if reward!=0:\n",
    "                results.append(1) \n",
    "            else:\n",
    "                results.append(0)    \n",
    "            break  \n",
    "        action=random.choice(env.validinputs)   \n",
    "        state, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            # result is -1 if the MCTS agent loses\n",
    "            if reward!=0:\n",
    "                results.append(-1) \n",
    "            else:\n",
    "                results.append(0)    \n",
    "            break  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0976f92",
   "metadata": {},
   "source": [
    "Half the time, the MCTS agent moves first so that no player has an advantage. We record a result of 1 if the MCTS agent wins and a result of -1 if the MCTS agent loses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebaa6e3",
   "metadata": {},
   "source": [
    "We now count how many times the MCTS agent with pruning has won and lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "572f5877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the MCTS agent has won 100 games\n",
      "the MCTS agent has lost 0 games\n",
      "the game has tied 0 times\n"
     ]
    }
   ],
   "source": [
    "# count how many times the MCTS agent won\n",
    "wins=results.count(1)\n",
    "print(f\"the MCTS agent has won {wins} games\")\n",
    "# count how many times the MCTS agent lost\n",
    "losses=results.count(-1)\n",
    "print(f\"the MCTS agent has lost {losses} games\")  \n",
    "# count how many tie games\n",
    "losses=results.count(0)\n",
    "print(f\"the game has tied {losses} times\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aac2a7",
   "metadata": {},
   "source": [
    "The above results show that the MCTS agent has won all 100 games."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
