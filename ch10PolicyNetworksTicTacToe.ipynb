{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653089c9",
   "metadata": {},
   "source": [
    "# Chapter 10: Policy Netwoks in Tic Tac Toe\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "*“All you need is lots and lots of data and lots of information about what the right\n",
    "answer is, and you’ll be able to train a big neural net to do what you want.”*\n",
    "\n",
    "-- Geoffrey Hinton\n",
    "***\n",
    "\n",
    "\n",
    "\n",
    "What you'll learn in this chapter:\n",
    "* What is a convolutional neural network\n",
    "* Building a fast policy network and a strong policy network in Tic Tac Toe\n",
    "* Generating expert moves to train the two policy networks in Tic Tac Toe\n",
    "* Implementing a mixed MCTS game strategy in Tic Tac Toe\n",
    "\n",
    "\n",
    "In the previous chapter, you learned the basics of deep learning and\n",
    "applied it to the coin game. Specifically, you generated expert moves in the\n",
    "game and used them to train two policy networks: a fast policy network with just\n",
    "one hidden layer and a strong policy network with three hidden layers.\n",
    "In this chapter, you’ll learn to use deep neural networks to train a fast policy network\n",
    "\n",
    "and a strong policy network in Tic Tac Toe. Different from the previous chapter, the\n",
    "two neural networks in this chapter include a new type of layers, convolutional layers,\n",
    "which are different from the fully-connected dense layer. While dense layers treat\n",
    "inputs as one-dimensional vectors, convolutional layers treat images or game boards\n",
    "as multi-dimensional objects and extract spatial features from them. Convolutional\n",
    "layers can greatly improve the predictive power of neural networks. This, in turn,\n",
    "makes the game strategies that use these policy networks more intelligent.\n",
    "\n",
    "To generate expert moves in Tic Tac Toe, you’ll use the MiniMax algorithm with\n",
    "alpha-beta pruning that we developed in Chapter 6. You’ll use the board positions as\n",
    "inputs (Xs) and the expert moves as the targets (ys). Since there are nine potential\n",
    "next moves for a player in each step, we’ll treat this as a multi-category classification\n",
    "problem and use supervised learning to train the two policy neural networks by using\n",
    "the board positions and expert moves. The two trained policy networks will be used\n",
    "in the AlphaGo algorithm later in this book.\n",
    "\n",
    "We’ll use the trained fast policy network later in the book to roll out games in MCTS\n",
    "when implementing the AlphaGo algorithm. In contrast, we’ll use the trained strong policy network to help select which next move to use when expanding the game\n",
    "tree in MCTS. To gain insight on how the strong policy network can be used in the\n",
    "final AlphaGo algorithm, you’ll learn to augment the Monte Carlo Tree Search with\n",
    "the trained strong policy network in this chapter. Specifically, instead of selecting\n",
    "moves based on upper confidence bounds for trees (UCT) scores alone, you’ll select\n",
    "moves based on both UCT scores and the probability distribution from the trained\n",
    "strong policy network.We call the agent who selects moves this way the mixed MCTS\n",
    "agent. You’ll show that the mixed MCTS agent is more intelligent than the traditional\n",
    "MCTS agent that you developed in Chapter 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ad876",
   "metadata": {},
   "source": [
    "# 1. What Are Convolutional Layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c9cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "board = np.array([[1,0,0],\n",
    "                   [1,-1,-1],\n",
    "                   [1,0,0]]).reshape(-1,3,3,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c62e1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vertical filter\n",
    "vertical_filter = np.array([[0,1,0], \n",
    "                   [0,1,0],\n",
    "                   [0,1,0]]).reshape(3,3,1,1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8a38b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2 -1 -1]\n",
      " [ 3 -1 -1]\n",
      " [ 2 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Apply the filter on the game board\n",
    "result=tf.nn.conv2d(board,vertical_filter,strides=1,padding=\"SAME\")\n",
    "# Print it results\n",
    "print(result.numpy().reshape(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcbdf00",
   "metadata": {},
   "source": [
    "# 2.  Deep Learning in Tic Tac Toe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8c5b19",
   "metadata": {},
   "source": [
    "## 2.2. Generate Expert Moves in Tic Tac Toe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2f8827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ch06util import MiniMax_ab\n",
    "\n",
    "def expert(env):\n",
    "    move = MiniMax_ab(env)\n",
    "    return move    \n",
    "\n",
    "def non_expert(env):\n",
    "    if np.random.rand()<0.5:\n",
    "        move = MiniMax_ab(env)\n",
    "    else:\n",
    "        move = env.sample()\n",
    "    return move  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db4ea45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([ 0,  0,  0,  0,  0,  0,  0, -1,  0]), 9), (array([ 0, -1,  0,  0,  0,  0,  0, -1,  1]), 5), (array([-1, -1,  0,  0,  1,  0,  0, -1,  1]), 3), (array([-1, -1,  1,  0,  1, -1,  0, -1,  1]), 7)]\n"
     ]
    }
   ],
   "source": [
    "from utils.ttt_simple_env import ttt\n",
    "from copy import deepcopy\n",
    "\n",
    "# Initiate the game environment\n",
    "env=ttt()\n",
    "# Define the one_game() function\n",
    "def one_game(episode):\n",
    "    history = []\n",
    "    state=env.reset()  \n",
    "    # The nonexpert moves firsts half the time\n",
    "    if episode%2==0:\n",
    "        action=non_expert(env)\n",
    "        state,reward,done,_=env.step(action)\n",
    "    while True:   \n",
    "        action=expert(env) \n",
    "        if episode%2==0:\n",
    "            statei=deepcopy(-state)\n",
    "        else:\n",
    "            statei=deepcopy(state)            \n",
    "        actioni=deepcopy(action)\n",
    "        # record board position and the move\n",
    "        history.append((statei,actioni))\n",
    "        state,reward,done,_=env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "        action=non_expert(env)\n",
    "        state,reward,done,_=env.step(action)     \n",
    "        if done:\n",
    "            break\n",
    "    return history\n",
    "\n",
    "# Simulate one game and print out results\n",
    "history=one_game(0)\n",
    "print(history)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a6a600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate the game 10000 times and record all games\n",
    "results = []        \n",
    "for episode in range(10000):\n",
    "    history=one_game(episode)\n",
    "    results+=history   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88782a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([ 0, -1,  0,  0,  0,  0,  0,  0,  0]), 5), (array([ 0, -1,  0,  0,  1,  0,  0, -1,  0]), 7), (array([-1, -1,  0,  0,  1,  0,  1, -1,  0]), 3), (array([0, 0, 0, 0, 0, 0, 0, 0, 0]), 6), (array([ 0,  0,  0, -1,  0,  1,  0,  0,  0]), 2), (array([ 0,  1,  0, -1,  0,  1,  0,  0, -1]), 8), (array([ 0,  1,  0, -1, -1,  1,  0,  1, -1]), 1), (array([ 1,  1, -1, -1, -1,  1,  0,  1, -1]), 7), (array([ 0,  0,  0,  0,  0,  0, -1,  0,  0]), 5), (array([ 0,  0, -1,  0,  1,  0, -1,  0,  0]), 2)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save the simulation data on your computer\n",
    "with open('files/games_ttt.p', 'wb') as fp:\n",
    "    pickle.dump(results,fp)\n",
    "# read the data and print out the first 10 observations       \n",
    "with open('files/games_ttt.p', 'rb') as fp:\n",
    "    games = pickle.load(fp)\n",
    "print(games[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e27a43",
   "metadata": {},
   "source": [
    "# 3. Two Policy Networks in Tic Tac Toe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8eed1",
   "metadata": {},
   "source": [
    "## 3.1. Create Two Neural Networks for Tic Tac Toe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1579eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten\n",
    "\n",
    "fast_model = Sequential()\n",
    "fast_model.add(Conv2D(filters=128, \n",
    "    kernel_size=(3,3),padding=\"same\",activation=\"relu\",\n",
    "                 input_shape=(3,3,1)))\n",
    "fast_model.add(Flatten())\n",
    "fast_model.add(Dense(units=64, activation=\"relu\"))\n",
    "fast_model.add(Dense(units=64, activation=\"relu\"))\n",
    "fast_model.add(Dense(9, activation='softmax'))\n",
    "fast_model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer='adam', \n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78d5c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_model = Sequential()\n",
    "strong_model.add(Conv2D(filters=128, \n",
    "    kernel_size=(3,3),padding=\"same\",activation=\"relu\",\n",
    "                 input_shape=(3,3,1)))\n",
    "strong_model.add(Flatten())\n",
    "strong_model.add(Dense(units=64, activation=\"relu\"))\n",
    "strong_model.add(Dense(units=64, activation=\"relu\"))\n",
    "strong_model.add(Dense(units=64, activation=\"relu\"))\n",
    "strong_model.add(Dense(9, activation='softmax'))\n",
    "strong_model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer='adam', \n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441286c7",
   "metadata": {},
   "source": [
    "## 3.2. Train the Two Policy Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31cfc31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "with open('files/games_ttt.p','rb') as fp:\n",
    "    games=pickle.load(fp)\n",
    "\n",
    "states=[]\n",
    "actions=[]\n",
    "for x in games:\n",
    "    state=x[0]\n",
    "    action=to_categorical(x[1]-1,9)\n",
    "    states.append(state)\n",
    "    actions.append(action)\n",
    "\n",
    "X=np.array(states).reshape((-1, 3, 3, 1))\n",
    "y=np.array(actions).reshape((-1, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3fc541a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1194/1194 [==============================] - 1s 951us/step - loss: 1.2428 - accuracy: 0.5271\n",
      "Epoch 2/100\n",
      "1194/1194 [==============================] - 1s 936us/step - loss: 0.9380 - accuracy: 0.6098\n",
      "Epoch 3/100\n",
      "1194/1194 [==============================] - 1s 932us/step - loss: 0.8894 - accuracy: 0.6182\n",
      "Epoch 4/100\n",
      "1194/1194 [==============================] - 1s 930us/step - loss: 0.8691 - accuracy: 0.6255\n",
      "Epoch 5/100\n",
      "1194/1194 [==============================] - 1s 942us/step - loss: 0.8545 - accuracy: 0.6248\n",
      "Epoch 6/100\n",
      "1194/1194 [==============================] - 1s 935us/step - loss: 0.8435 - accuracy: 0.6295\n",
      "Epoch 7/100\n",
      "1194/1194 [==============================] - 1s 934us/step - loss: 0.8368 - accuracy: 0.6306\n",
      "Epoch 8/100\n",
      "1194/1194 [==============================] - 1s 943us/step - loss: 0.8315 - accuracy: 0.6286\n",
      "Epoch 9/100\n",
      "1194/1194 [==============================] - 1s 944us/step - loss: 0.8249 - accuracy: 0.6313\n",
      "Epoch 10/100\n",
      "1194/1194 [==============================] - 1s 944us/step - loss: 0.8228 - accuracy: 0.6294\n",
      "Epoch 11/100\n",
      "1194/1194 [==============================] - 1s 935us/step - loss: 0.8190 - accuracy: 0.6314\n",
      "Epoch 12/100\n",
      "1194/1194 [==============================] - 1s 938us/step - loss: 0.8156 - accuracy: 0.6285\n",
      "Epoch 13/100\n",
      "1194/1194 [==============================] - 1s 937us/step - loss: 0.8127 - accuracy: 0.6312\n",
      "Epoch 14/100\n",
      "1194/1194 [==============================] - 1s 927us/step - loss: 0.8101 - accuracy: 0.6301\n",
      "Epoch 15/100\n",
      "1194/1194 [==============================] - 1s 941us/step - loss: 0.8058 - accuracy: 0.6334\n",
      "Epoch 16/100\n",
      "1194/1194 [==============================] - 1s 930us/step - loss: 0.8034 - accuracy: 0.6350\n",
      "Epoch 17/100\n",
      "1194/1194 [==============================] - 1s 947us/step - loss: 0.8002 - accuracy: 0.6344\n",
      "Epoch 18/100\n",
      "1194/1194 [==============================] - 1s 924us/step - loss: 0.8005 - accuracy: 0.6320\n",
      "Epoch 19/100\n",
      "1194/1194 [==============================] - 1s 930us/step - loss: 0.7977 - accuracy: 0.6339\n",
      "Epoch 20/100\n",
      "1194/1194 [==============================] - 1s 950us/step - loss: 0.7949 - accuracy: 0.6345\n",
      "Epoch 21/100\n",
      "1194/1194 [==============================] - 1s 939us/step - loss: 0.7938 - accuracy: 0.6352\n",
      "Epoch 22/100\n",
      "1194/1194 [==============================] - 1s 934us/step - loss: 0.7913 - accuracy: 0.6357\n",
      "Epoch 23/100\n",
      "1194/1194 [==============================] - 1s 935us/step - loss: 0.7913 - accuracy: 0.6362\n",
      "Epoch 24/100\n",
      "1194/1194 [==============================] - 1s 934us/step - loss: 0.7895 - accuracy: 0.6355\n",
      "Epoch 25/100\n",
      "1194/1194 [==============================] - 1s 941us/step - loss: 0.7884 - accuracy: 0.6342\n",
      "Epoch 26/100\n",
      "1194/1194 [==============================] - 1s 940us/step - loss: 0.7865 - accuracy: 0.6351\n",
      "Epoch 27/100\n",
      "1194/1194 [==============================] - 1s 942us/step - loss: 0.7852 - accuracy: 0.6368\n",
      "Epoch 28/100\n",
      "1194/1194 [==============================] - 1s 938us/step - loss: 0.7835 - accuracy: 0.6350\n",
      "Epoch 29/100\n",
      "1194/1194 [==============================] - 1s 940us/step - loss: 0.7833 - accuracy: 0.6372\n",
      "Epoch 30/100\n",
      "1194/1194 [==============================] - 1s 934us/step - loss: 0.7821 - accuracy: 0.6370\n",
      "Epoch 31/100\n",
      "1194/1194 [==============================] - 1s 947us/step - loss: 0.7813 - accuracy: 0.6362\n",
      "Epoch 32/100\n",
      "1194/1194 [==============================] - 1s 942us/step - loss: 0.7797 - accuracy: 0.6368\n",
      "Epoch 33/100\n",
      "1194/1194 [==============================] - 1s 946us/step - loss: 0.7777 - accuracy: 0.6375\n",
      "Epoch 34/100\n",
      "1194/1194 [==============================] - 1s 952us/step - loss: 0.7776 - accuracy: 0.6392\n",
      "Epoch 35/100\n",
      "1194/1194 [==============================] - 1s 947us/step - loss: 0.7775 - accuracy: 0.6369\n",
      "Epoch 36/100\n",
      "1194/1194 [==============================] - 1s 945us/step - loss: 0.7762 - accuracy: 0.6372\n",
      "Epoch 37/100\n",
      "1194/1194 [==============================] - 1s 952us/step - loss: 0.7755 - accuracy: 0.6384\n",
      "Epoch 38/100\n",
      "1194/1194 [==============================] - 1s 948us/step - loss: 0.7741 - accuracy: 0.6390\n",
      "Epoch 39/100\n",
      "1194/1194 [==============================] - 1s 943us/step - loss: 0.7736 - accuracy: 0.6388\n",
      "Epoch 40/100\n",
      "1194/1194 [==============================] - 1s 945us/step - loss: 0.7731 - accuracy: 0.6369\n",
      "Epoch 41/100\n",
      "1194/1194 [==============================] - 1s 957us/step - loss: 0.7715 - accuracy: 0.6371\n",
      "Epoch 42/100\n",
      "1194/1194 [==============================] - 1s 952us/step - loss: 0.7716 - accuracy: 0.6432\n",
      "Epoch 43/100\n",
      "1194/1194 [==============================] - 1s 943us/step - loss: 0.7708 - accuracy: 0.6379\n",
      "Epoch 44/100\n",
      "1194/1194 [==============================] - 1s 965us/step - loss: 0.7689 - accuracy: 0.6375\n",
      "Epoch 45/100\n",
      "1194/1194 [==============================] - 1s 991us/step - loss: 0.7685 - accuracy: 0.6401\n",
      "Epoch 46/100\n",
      "1194/1194 [==============================] - 1s 963us/step - loss: 0.7678 - accuracy: 0.6413\n",
      "Epoch 47/100\n",
      "1194/1194 [==============================] - 1s 955us/step - loss: 0.7693 - accuracy: 0.6396\n",
      "Epoch 48/100\n",
      "1194/1194 [==============================] - 1s 964us/step - loss: 0.7664 - accuracy: 0.6416\n",
      "Epoch 49/100\n",
      "1194/1194 [==============================] - 1s 954us/step - loss: 0.7659 - accuracy: 0.6418\n",
      "Epoch 50/100\n",
      "1194/1194 [==============================] - 1s 959us/step - loss: 0.7676 - accuracy: 0.6400\n",
      "Epoch 51/100\n",
      "1194/1194 [==============================] - 1s 938us/step - loss: 0.7656 - accuracy: 0.6411\n",
      "Epoch 52/100\n",
      "1194/1194 [==============================] - 1s 954us/step - loss: 0.7644 - accuracy: 0.6408\n",
      "Epoch 53/100\n",
      "1194/1194 [==============================] - 1s 941us/step - loss: 0.7657 - accuracy: 0.6434\n",
      "Epoch 54/100\n",
      "1194/1194 [==============================] - 1s 985us/step - loss: 0.7634 - accuracy: 0.6420\n",
      "Epoch 55/100\n",
      "1194/1194 [==============================] - 1s 982us/step - loss: 0.7653 - accuracy: 0.6427\n",
      "Epoch 56/100\n",
      "1194/1194 [==============================] - 1s 955us/step - loss: 0.7616 - accuracy: 0.6432\n",
      "Epoch 57/100\n",
      "1194/1194 [==============================] - 1s 942us/step - loss: 0.7644 - accuracy: 0.6413\n",
      "Epoch 58/100\n",
      "1194/1194 [==============================] - 1s 947us/step - loss: 0.7630 - accuracy: 0.6425\n",
      "Epoch 59/100\n",
      "1194/1194 [==============================] - 1s 947us/step - loss: 0.7620 - accuracy: 0.6420\n",
      "Epoch 60/100\n",
      "1194/1194 [==============================] - 1s 948us/step - loss: 0.7612 - accuracy: 0.6424\n",
      "Epoch 61/100\n",
      "1194/1194 [==============================] - 1s 950us/step - loss: 0.7614 - accuracy: 0.6439\n",
      "Epoch 62/100\n",
      "1194/1194 [==============================] - 1s 940us/step - loss: 0.7615 - accuracy: 0.6438\n",
      "Epoch 63/100\n",
      "1194/1194 [==============================] - 1s 943us/step - loss: 0.7618 - accuracy: 0.6423\n",
      "Epoch 64/100\n",
      "1194/1194 [==============================] - 1s 943us/step - loss: 0.7637 - accuracy: 0.6419\n",
      "Epoch 65/100\n",
      "1194/1194 [==============================] - 1s 943us/step - loss: 0.7590 - accuracy: 0.6425\n",
      "Epoch 66/100\n",
      "1194/1194 [==============================] - 1s 948us/step - loss: 0.7603 - accuracy: 0.6423\n",
      "Epoch 67/100\n",
      "1194/1194 [==============================] - 1s 952us/step - loss: 0.7602 - accuracy: 0.6422\n",
      "Epoch 68/100\n",
      "1194/1194 [==============================] - 1s 952us/step - loss: 0.7621 - accuracy: 0.6436\n",
      "Epoch 69/100\n",
      "1194/1194 [==============================] - 1s 956us/step - loss: 0.7586 - accuracy: 0.6446\n",
      "Epoch 70/100\n",
      "1194/1194 [==============================] - 1s 954us/step - loss: 0.7607 - accuracy: 0.6438\n",
      "Epoch 71/100\n",
      "1194/1194 [==============================] - 1s 956us/step - loss: 0.7587 - accuracy: 0.6443\n",
      "Epoch 72/100\n",
      "1194/1194 [==============================] - 1s 972us/step - loss: 0.7613 - accuracy: 0.6448\n",
      "Epoch 73/100\n",
      "1194/1194 [==============================] - 1s 968us/step - loss: 0.7578 - accuracy: 0.6442\n",
      "Epoch 74/100\n",
      "1194/1194 [==============================] - 1s 981us/step - loss: 0.7579 - accuracy: 0.6455\n",
      "Epoch 75/100\n",
      "1194/1194 [==============================] - 1s 957us/step - loss: 0.7631 - accuracy: 0.6434\n",
      "Epoch 76/100\n",
      "1194/1194 [==============================] - 1s 953us/step - loss: 0.7585 - accuracy: 0.6467\n",
      "Epoch 77/100\n",
      "1194/1194 [==============================] - 1s 961us/step - loss: 0.7583 - accuracy: 0.6461\n",
      "Epoch 78/100\n",
      "1194/1194 [==============================] - 1s 958us/step - loss: 0.7585 - accuracy: 0.6440\n",
      "Epoch 79/100\n",
      "1194/1194 [==============================] - 1s 945us/step - loss: 0.7573 - accuracy: 0.6461\n",
      "Epoch 80/100\n",
      "1194/1194 [==============================] - 1s 965us/step - loss: 0.7604 - accuracy: 0.6471\n",
      "Epoch 81/100\n",
      "1194/1194 [==============================] - 1s 954us/step - loss: 0.7594 - accuracy: 0.6442\n",
      "Epoch 82/100\n",
      "1194/1194 [==============================] - 1s 952us/step - loss: 0.7593 - accuracy: 0.6455\n",
      "Epoch 83/100\n",
      "1194/1194 [==============================] - 1s 946us/step - loss: 0.7585 - accuracy: 0.6454\n",
      "Epoch 84/100\n",
      "1194/1194 [==============================] - 1s 965us/step - loss: 0.7574 - accuracy: 0.6463\n",
      "Epoch 85/100\n",
      "1194/1194 [==============================] - 1s 948us/step - loss: 0.7574 - accuracy: 0.6462\n",
      "Epoch 86/100\n",
      "1194/1194 [==============================] - 1s 963us/step - loss: 0.7587 - accuracy: 0.6456\n",
      "Epoch 87/100\n",
      "1194/1194 [==============================] - 1s 945us/step - loss: 0.7576 - accuracy: 0.6461\n",
      "Epoch 88/100\n",
      "1194/1194 [==============================] - 1s 959us/step - loss: 0.7576 - accuracy: 0.6452\n",
      "Epoch 89/100\n",
      "1194/1194 [==============================] - 1s 968us/step - loss: 0.7571 - accuracy: 0.6461\n",
      "Epoch 90/100\n",
      "1194/1194 [==============================] - 1s 952us/step - loss: 0.7596 - accuracy: 0.6454\n",
      "Epoch 91/100\n",
      "1194/1194 [==============================] - 1s 958us/step - loss: 0.7594 - accuracy: 0.6460\n",
      "Epoch 92/100\n",
      "1194/1194 [==============================] - 1s 941us/step - loss: 0.7566 - accuracy: 0.6461\n",
      "Epoch 93/100\n",
      "1194/1194 [==============================] - 1s 956us/step - loss: 0.7593 - accuracy: 0.6450\n",
      "Epoch 94/100\n",
      "1194/1194 [==============================] - 1s 944us/step - loss: 0.7575 - accuracy: 0.6470\n",
      "Epoch 95/100\n",
      "1194/1194 [==============================] - 1s 935us/step - loss: 0.7592 - accuracy: 0.6467\n",
      "Epoch 96/100\n",
      "1194/1194 [==============================] - 1s 934us/step - loss: 0.7554 - accuracy: 0.6477\n",
      "Epoch 97/100\n",
      "1194/1194 [==============================] - 1s 980us/step - loss: 0.7597 - accuracy: 0.6456\n",
      "Epoch 98/100\n",
      "1194/1194 [==============================] - 1s 945us/step - loss: 0.7570 - accuracy: 0.6470\n",
      "Epoch 99/100\n",
      "1194/1194 [==============================] - 1s 935us/step - loss: 0.7557 - accuracy: 0.6475\n",
      "Epoch 100/100\n",
      "1194/1194 [==============================] - 1s 922us/step - loss: 0.7565 - accuracy: 0.6461\n"
     ]
    }
   ],
   "source": [
    "# Train the fast policy network for 100 epochs\n",
    "fast_model.fit(X, y, epochs=100, verbose=1)\n",
    "fast_model.save('files/fast_ttt.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b21ec5",
   "metadata": {},
   "source": [
    "It takes about five minutes to train the model. Once done, we save the trained model in the local foder. \n",
    "\n",
    "Next, we train the strong policy network for 100 epochs as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf390256",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1194/1194 [==============================] - 2s 980us/step - loss: 1.2319 - accuracy: 0.5284\n",
      "Epoch 2/100\n",
      "1194/1194 [==============================] - 1s 966us/step - loss: 0.9242 - accuracy: 0.6122\n",
      "Epoch 3/100\n",
      "1194/1194 [==============================] - 1s 968us/step - loss: 0.8795 - accuracy: 0.6219\n",
      "Epoch 4/100\n",
      "1194/1194 [==============================] - 1s 964us/step - loss: 0.8559 - accuracy: 0.6259\n",
      "Epoch 5/100\n",
      "1194/1194 [==============================] - 1s 958us/step - loss: 0.8442 - accuracy: 0.6286\n",
      "Epoch 6/100\n",
      "1194/1194 [==============================] - 1s 956us/step - loss: 0.8322 - accuracy: 0.6302\n",
      "Epoch 7/100\n",
      "1194/1194 [==============================] - 1s 958us/step - loss: 0.8260 - accuracy: 0.6314\n",
      "Epoch 8/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.8219 - accuracy: 0.6306\n",
      "Epoch 9/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.8152 - accuracy: 0.6318\n",
      "Epoch 10/100\n",
      "1194/1194 [==============================] - 1s 970us/step - loss: 0.8107 - accuracy: 0.6334\n",
      "Epoch 11/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.8084 - accuracy: 0.6307\n",
      "Epoch 12/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.8028 - accuracy: 0.6334\n",
      "Epoch 13/100\n",
      "1194/1194 [==============================] - 1s 976us/step - loss: 0.8006 - accuracy: 0.6349\n",
      "Epoch 14/100\n",
      "1194/1194 [==============================] - 1s 972us/step - loss: 0.7974 - accuracy: 0.6352\n",
      "Epoch 15/100\n",
      "1194/1194 [==============================] - 1s 967us/step - loss: 0.7939 - accuracy: 0.6368\n",
      "Epoch 16/100\n",
      "1194/1194 [==============================] - 1s 966us/step - loss: 0.7909 - accuracy: 0.6363\n",
      "Epoch 17/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.7889 - accuracy: 0.6368\n",
      "Epoch 18/100\n",
      "1194/1194 [==============================] - 1s 970us/step - loss: 0.7881 - accuracy: 0.6347\n",
      "Epoch 19/100\n",
      "1194/1194 [==============================] - 1s 975us/step - loss: 0.7844 - accuracy: 0.6364\n",
      "Epoch 20/100\n",
      "1194/1194 [==============================] - 1s 966us/step - loss: 0.7811 - accuracy: 0.6390\n",
      "Epoch 21/100\n",
      "1194/1194 [==============================] - 1s 952us/step - loss: 0.7823 - accuracy: 0.6356\n",
      "Epoch 22/100\n",
      "1194/1194 [==============================] - 1s 958us/step - loss: 0.7784 - accuracy: 0.6366\n",
      "Epoch 23/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.7800 - accuracy: 0.6370\n",
      "Epoch 24/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.7757 - accuracy: 0.6386\n",
      "Epoch 25/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.7768 - accuracy: 0.6381\n",
      "Epoch 26/100\n",
      "1194/1194 [==============================] - 1s 998us/step - loss: 0.7745 - accuracy: 0.6367\n",
      "Epoch 27/100\n",
      "1194/1194 [==============================] - 1s 976us/step - loss: 0.7712 - accuracy: 0.6381\n",
      "Epoch 28/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.7719 - accuracy: 0.6390\n",
      "Epoch 29/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.7710 - accuracy: 0.6389\n",
      "Epoch 30/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.7697 - accuracy: 0.6419\n",
      "Epoch 31/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.7697 - accuracy: 0.6406\n",
      "Epoch 32/100\n",
      "1194/1194 [==============================] - 1s 976us/step - loss: 0.7706 - accuracy: 0.6386\n",
      "Epoch 33/100\n",
      "1194/1194 [==============================] - 1s 972us/step - loss: 0.7668 - accuracy: 0.6374\n",
      "Epoch 34/100\n",
      "1194/1194 [==============================] - 1s 971us/step - loss: 0.7657 - accuracy: 0.6405\n",
      "Epoch 35/100\n",
      "1194/1194 [==============================] - 1s 981us/step - loss: 0.7681 - accuracy: 0.6402\n",
      "Epoch 36/100\n",
      "1194/1194 [==============================] - 1s 973us/step - loss: 0.7660 - accuracy: 0.6396\n",
      "Epoch 37/100\n",
      "1194/1194 [==============================] - 1s 963us/step - loss: 0.7695 - accuracy: 0.6443\n",
      "Epoch 38/100\n",
      "1194/1194 [==============================] - 1s 980us/step - loss: 0.7655 - accuracy: 0.6407\n",
      "Epoch 39/100\n",
      "1194/1194 [==============================] - 1s 976us/step - loss: 0.7639 - accuracy: 0.6431\n",
      "Epoch 40/100\n",
      "1194/1194 [==============================] - 1s 974us/step - loss: 0.7663 - accuracy: 0.6415\n",
      "Epoch 41/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.7686 - accuracy: 0.6415\n",
      "Epoch 42/100\n",
      "1194/1194 [==============================] - 1s 974us/step - loss: 0.7617 - accuracy: 0.6410\n",
      "Epoch 43/100\n",
      "1194/1194 [==============================] - 1s 967us/step - loss: 0.7652 - accuracy: 0.6439\n",
      "Epoch 44/100\n",
      "1194/1194 [==============================] - 1s 980us/step - loss: 0.7617 - accuracy: 0.6426\n",
      "Epoch 45/100\n",
      "1194/1194 [==============================] - 1s 963us/step - loss: 0.7629 - accuracy: 0.6424\n",
      "Epoch 46/100\n",
      "1194/1194 [==============================] - 1s 985us/step - loss: 0.7646 - accuracy: 0.6423\n",
      "Epoch 47/100\n",
      "1194/1194 [==============================] - 1s 987us/step - loss: 0.7616 - accuracy: 0.6428\n",
      "Epoch 48/100\n",
      "1194/1194 [==============================] - 1s 1ms/step - loss: 0.7620 - accuracy: 0.6417\n",
      "Epoch 49/100\n",
      "1194/1194 [==============================] - 1s 981us/step - loss: 0.7663 - accuracy: 0.6418\n",
      "Epoch 50/100\n",
      "1194/1194 [==============================] - 1s 970us/step - loss: 0.7609 - accuracy: 0.6438\n",
      "Epoch 51/100\n",
      "1194/1194 [==============================] - 1s 978us/step - loss: 0.7596 - accuracy: 0.6431\n",
      "Epoch 52/100\n",
      "1194/1194 [==============================] - 1s 974us/step - loss: 0.7645 - accuracy: 0.6433\n",
      "Epoch 53/100\n",
      "1194/1194 [==============================] - 1s 972us/step - loss: 0.7608 - accuracy: 0.6418\n",
      "Epoch 54/100\n",
      "1194/1194 [==============================] - 1s 984us/step - loss: 0.7630 - accuracy: 0.6438\n",
      "Epoch 55/100\n",
      "1194/1194 [==============================] - 1s 975us/step - loss: 0.7598 - accuracy: 0.6452\n",
      "Epoch 56/100\n",
      "1194/1194 [==============================] - 1s 985us/step - loss: 0.7638 - accuracy: 0.6451\n",
      "Epoch 57/100\n",
      "1194/1194 [==============================] - 1s 978us/step - loss: 0.7641 - accuracy: 0.6429\n",
      "Epoch 58/100\n",
      "1194/1194 [==============================] - 1s 989us/step - loss: 0.7587 - accuracy: 0.6438\n",
      "Epoch 59/100\n",
      "1194/1194 [==============================] - 1s 992us/step - loss: 0.7581 - accuracy: 0.6440\n",
      "Epoch 60/100\n",
      "1194/1194 [==============================] - 1s 985us/step - loss: 0.7647 - accuracy: 0.6424\n",
      "Epoch 61/100\n",
      "1194/1194 [==============================] - 1s 985us/step - loss: 0.7586 - accuracy: 0.6448\n",
      "Epoch 62/100\n",
      "1194/1194 [==============================] - 1s 985us/step - loss: 0.7585 - accuracy: 0.6451\n",
      "Epoch 63/100\n",
      "1194/1194 [==============================] - 1s 984us/step - loss: 0.7597 - accuracy: 0.6450\n",
      "Epoch 64/100\n",
      "1194/1194 [==============================] - 1s 994us/step - loss: 0.7639 - accuracy: 0.6426\n",
      "Epoch 65/100\n",
      "1194/1194 [==============================] - 1s 994us/step - loss: 0.7598 - accuracy: 0.6445\n",
      "Epoch 66/100\n",
      "1194/1194 [==============================] - 1s 980us/step - loss: 0.7592 - accuracy: 0.6446\n",
      "Epoch 67/100\n",
      "1194/1194 [==============================] - 1s 970us/step - loss: 0.7579 - accuracy: 0.6459\n",
      "Epoch 68/100\n",
      "1194/1194 [==============================] - 1s 976us/step - loss: 0.7634 - accuracy: 0.6454\n",
      "Epoch 69/100\n",
      "1194/1194 [==============================] - 1s 981us/step - loss: 0.7566 - accuracy: 0.6457\n",
      "Epoch 70/100\n",
      "1194/1194 [==============================] - 1s 978us/step - loss: 0.7585 - accuracy: 0.6459\n",
      "Epoch 71/100\n",
      "1194/1194 [==============================] - 1s 965us/step - loss: 0.7633 - accuracy: 0.6450\n",
      "Epoch 72/100\n",
      "1194/1194 [==============================] - 1s 981us/step - loss: 0.7625 - accuracy: 0.6451\n",
      "Epoch 73/100\n",
      "1194/1194 [==============================] - 1s 974us/step - loss: 0.7563 - accuracy: 0.6456\n",
      "Epoch 74/100\n",
      "1194/1194 [==============================] - 1s 975us/step - loss: 0.7579 - accuracy: 0.6454\n",
      "Epoch 75/100\n",
      "1194/1194 [==============================] - 1s 979us/step - loss: 0.7598 - accuracy: 0.6465\n",
      "Epoch 76/100\n",
      "1194/1194 [==============================] - 1s 982us/step - loss: 0.7597 - accuracy: 0.6448\n",
      "Epoch 77/100\n",
      "1194/1194 [==============================] - 1s 1ms/step - loss: 0.7627 - accuracy: 0.6450\n",
      "Epoch 78/100\n",
      "1194/1194 [==============================] - 1s 989us/step - loss: 0.7572 - accuracy: 0.6448\n",
      "Epoch 79/100\n",
      "1194/1194 [==============================] - 1s 983us/step - loss: 0.7583 - accuracy: 0.6463\n",
      "Epoch 80/100\n",
      "1194/1194 [==============================] - 1s 980us/step - loss: 0.7573 - accuracy: 0.6443\n",
      "Epoch 81/100\n",
      "1194/1194 [==============================] - 1s 982us/step - loss: 0.7608 - accuracy: 0.6450\n",
      "Epoch 82/100\n",
      "1194/1194 [==============================] - 1s 967us/step - loss: 0.7603 - accuracy: 0.6467\n",
      "Epoch 83/100\n",
      "1194/1194 [==============================] - 1s 981us/step - loss: 0.7571 - accuracy: 0.6466\n",
      "Epoch 84/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.7568 - accuracy: 0.6460\n",
      "Epoch 85/100\n",
      "1194/1194 [==============================] - 1s 973us/step - loss: 0.7631 - accuracy: 0.6463\n",
      "Epoch 86/100\n",
      "1194/1194 [==============================] - 1s 965us/step - loss: 0.7593 - accuracy: 0.6452\n",
      "Epoch 87/100\n",
      "1194/1194 [==============================] - 1s 970us/step - loss: 0.7563 - accuracy: 0.6468\n",
      "Epoch 88/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.7568 - accuracy: 0.6460\n",
      "Epoch 89/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.7632 - accuracy: 0.6449\n",
      "Epoch 90/100\n",
      "1194/1194 [==============================] - 1s 978us/step - loss: 0.7573 - accuracy: 0.6467\n",
      "Epoch 91/100\n",
      "1194/1194 [==============================] - 1s 960us/step - loss: 0.7607 - accuracy: 0.6436\n",
      "Epoch 92/100\n",
      "1194/1194 [==============================] - 1s 974us/step - loss: 0.7574 - accuracy: 0.6474\n",
      "Epoch 93/100\n",
      "1194/1194 [==============================] - 1s 974us/step - loss: 0.7572 - accuracy: 0.6467\n",
      "Epoch 94/100\n",
      "1194/1194 [==============================] - 1s 968us/step - loss: 0.7617 - accuracy: 0.6450\n",
      "Epoch 95/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.7558 - accuracy: 0.6469\n",
      "Epoch 96/100\n",
      "1194/1194 [==============================] - 1s 969us/step - loss: 0.7556 - accuracy: 0.6479\n",
      "Epoch 97/100\n",
      "1194/1194 [==============================] - 1s 983us/step - loss: 0.7614 - accuracy: 0.6477\n",
      "Epoch 98/100\n",
      "1194/1194 [==============================] - 1s 979us/step - loss: 0.7626 - accuracy: 0.6449\n",
      "Epoch 99/100\n",
      "1194/1194 [==============================] - 1s 973us/step - loss: 0.7553 - accuracy: 0.6472\n",
      "Epoch 100/100\n",
      "1194/1194 [==============================] - 1s 964us/step - loss: 0.7568 - accuracy: 0.6473\n"
     ]
    }
   ],
   "source": [
    "strong_model.fit(X, y, epochs=100, verbose=1)\n",
    "strong_model.save('files/strong_ttt.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14805aac",
   "metadata": {},
   "source": [
    "# 4. A Mixed MCTS Algorithm\n",
    " \n",
    "\n",
    "## 4.1 Augment the UCT formula with a strong policy network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a934805a",
   "metadata": {},
   "source": [
    "## 4.2. Mixed MCTS in Tic Tac Toe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b136b48",
   "metadata": {},
   "source": [
    "In the local module *ch10util*, we define a *mix_select()* function as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c7265",
   "metadata": {},
   "source": [
    "```python\n",
    "gamma=10\n",
    "def mix_select(env,ps,counts,wins,losses,temperature):\n",
    "    # a dictionary of mixed scores for all next moves\n",
    "    scores={}\n",
    "    # the ones not visited get the priority\n",
    "    for k in env.validinputs:\n",
    "        if counts[k]==0:\n",
    "            return k\n",
    "    # total number of simulations conducted\n",
    "    N=sum([v for k,v in counts.items()])\n",
    "    # calculate scores\n",
    "    for k,v in counts.items():\n",
    "        # the third term based on policy network\n",
    "        weighted_pi=gamma*ps[k]/(1+counts[k])       \n",
    "        if v==0:\n",
    "            scores[k]=weighted_pi\n",
    "        else:\n",
    "            # vi for each next move\n",
    "            vi=(wins.get(k,0)-losses.get(k,0))/v\n",
    "            # exploratoin term\n",
    "            exploration=temperature*sqrt(log(N)/counts[k])\n",
    "            # mixed score\n",
    "            scores[k]=vi+exploration+weighted_pi\n",
    "    # Select the next move with the highest UCT score\n",
    "    return max(scores,key=scores.get)  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72009532",
   "metadata": {},
   "source": [
    "```python\n",
    "def next_move(ps,counts,wins,losses):\n",
    "    # See which action is most promising\n",
    "    scores={}    \n",
    "    # calculate scores\n",
    "    for k,v in counts.items():\n",
    "        # the third term based on policy network\n",
    "        weighted_pi=gamma*ps[k]/(1+counts[k])       \n",
    "        # vi for each next move\n",
    "        vi=(wins.get(k,0)-losses.get(k,0))/v\n",
    "        # mixed score\n",
    "        scores[k]=vi+weighted_pi\n",
    "    # Select the next move with the score\n",
    "    return max(scores,key=scores.get)  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b2b05e",
   "metadata": {},
   "source": [
    "```python\n",
    "def mix_mcts(env,model,num_rollouts=100,temperature=1.4):\n",
    "    # if there is only one valid move left, take it\n",
    "    if len(env.validinputs)==1:\n",
    "        return env.validinputs[0]\n",
    "    # create three dictionaries counts, wins, losses\n",
    "    counts={}\n",
    "    wins={}\n",
    "    losses={}\n",
    "    for move in env.validinputs:\n",
    "        counts[move]=0\n",
    "        wins[move]=0\n",
    "        losses[move]=0\n",
    "    # priors from the policy network\n",
    "    state = env.state.reshape(-1,3,3,1)\n",
    "    if env.turn==\"X\":\n",
    "        action_probs= model(state)\n",
    "    else:\n",
    "        action_probs= model(-state)     \n",
    "    ps={}\n",
    "    for a in sorted(env.validinputs):\n",
    "        ps[a]=np.squeeze(action_probs)[a-1]    \n",
    "    # roll out games\n",
    "    for _ in range(num_rollouts):\n",
    "        # selection\n",
    "        move=mix_select(env,ps,counts,wins,losses,temperature)\n",
    "        # expansion\n",
    "        env_copy, done, reward=expand(env,move)\n",
    "        # simulation\n",
    "        reward=simulate(env_copy,done,reward)      \n",
    "        # backpropagate\n",
    "        counts,wins,losses=backpropagate(\\\n",
    "            env,move,reward,counts,wins,losses)\n",
    "    # make the move\n",
    "    return next_move(ps,counts,wins,losses)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0e0986",
   "metadata": {},
   "source": [
    "# 5. Mixed MCTS versus UCT MCTS\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c8e35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ttt_simple_env import ttt\n",
    "from utils.ch10util import mix_mcts\n",
    "from utils.ch08util import mcts\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load the trained strong policy network\n",
    "model=load_model(\"files/strong_ttt.h5\")\n",
    "\n",
    "# Initiate the game environment\n",
    "env=ttt()\n",
    "state=env.reset() \n",
    "num_rollouts=200\n",
    "results=[]\n",
    "for i in range(100):\n",
    "    state=env.reset() \n",
    "    if i%2==0:\n",
    "        action=mcts(env,num_rollouts=num_rollouts)\n",
    "        state, reward, done, info = env.step(action)\n",
    "    while True:\n",
    "        action=mix_mcts(env,model,num_rollouts=num_rollouts)  \n",
    "        state, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            # result is 1 if mixed MCTS wins\n",
    "            if reward!=0:\n",
    "                results.append(1) \n",
    "            else:\n",
    "                results.append(0)    \n",
    "            break  \n",
    "        action=mcts(env,num_rollouts=num_rollouts)   \n",
    "        state, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            # result is -1 if mixed MCTS loses\n",
    "            if reward!=0:\n",
    "                results.append(-1) \n",
    "            else:\n",
    "                results.append(0)    \n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ee606e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed MCTS won 30 games\n",
      "mixed MCTS lost 7 games\n",
      "the game is tied 63 times\n"
     ]
    }
   ],
   "source": [
    "# count how many times mixed MCTS won\n",
    "wins=results.count(1)\n",
    "print(f\"mixed MCTS won {wins} games\")\n",
    "# count how many times mix MCTS lost\n",
    "losses=results.count(-1)\n",
    "print(f\"mixed MCTS lost {losses} games\")  \n",
    "# count how many tie games\n",
    "ties=results.count(0)\n",
    "print(f\"the game is tied {ties} times\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
